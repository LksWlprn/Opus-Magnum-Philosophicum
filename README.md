# Metaphysics


## On Ontology

### Existence
The most fundamental metaphysical question is: Why is there anything at all? Until recently, science could not help us in answering this question, but I now believe that it can. 

Since nothing can come from nothing, absolute nothingness should persist, yet reality exists. 
One possible answer, the zero-ontology, holds that reality can be both there and not there and sums to nothing overall, much like how matter and antimatter cancel out. But this isn't more than a hunch.
A better approach begins by examining the nature of nothingness. 
One kind of nothingness from which everything could have started is the total absence of anything. This would include the lack of any boundary conditions, since there would have to be something to define a boundary condition. There cannot be any definitions in such nothingness. 
Yet, this absence of constraints would itself be a constraint (a definition), meaning that absolute nothingness contradicts itself and is impossible. It will become clear, when considering my thoughts on epistemology, that contradiction is the only ultimate truth-finding tool we possess. Logical contradiction is the only true impossibility, and even nothingness cannot contradict itself, for it needs to be in the realm of possibility. The only non-contradictory kind of nothingness would be one that is at least definable: 
a state of complete emptiness, where empty does not mean empty spacetime, but rather spacelessness and timelessness. But in such a state necessary truths, meaning logical truths, are still necessarily existent. 
If they did not exist, there would be no constraints on reality at all, allowing anything to exist arbitrarily, which would be exactly the contradictory form of nothingness we already ruled out as self-defeating. Necessary truths must exist necessarily. 
There are infinitely many possible formal systems, and all such systems must exist in an abstract sense. This corresponds to Stephen Wolfram’s Ruliad, the space of all possible rule-based structures, within which our universe is a fragment. 
Therefore, I claim that Wolfram's model of everything must be, from logical a priori reasoning alone, very close to being the correct model of everything, given our evidence that something exists at all.

Wolfram himself comes to the same conclusion: "The set of all possible rules is something purely formal. It can be represented in an infinite number of ways. But it’s always there, existing as an abstract thing, completely independent of any particular instantiation.
It’s crucial that we’re talking about all possible rules. If we were talking about particular rules, then we’d need to specify which rules those are, and we’d need a whole language and structure for doing that. But that’s not our situation. We’re talking about all possible rules. We can construct some explicit symbolic representation for these rules, but the deductions we make ultimately won’t depend on this; they would work the same whatever representation we chose to construct.
We might have assumed that to get our universe we’d need some definite input, some specific information. But what we’re discovering is that our universe is in some sense like a tautology; it’s something that has to be the way it is just because of the definition of terms. In effect, it exists because it has to, or in a sense because everything about it is a “logical inevitability”, with no choice about anything. [...] At some level, we can just think of rules abstractly being applied. But in our models of physics, there’s an interpretation of that: sequences of rules being applied define the passage of time. There are “logically inevitable” chains of rule applications. But for us as observers embedded in the system—particularly with our way of setting up our thread of consciousness—we perceive this as time passing, or in effect, “things happening in the universe”.
Talking about things this way might lead one to ask “What got the universe started?” “What makes rules actually get applied?” Well, nothing. Because the rules are just defining how abstract sequences can be constructed. And if you follow a sequence, it can be interpreted as reflecting the passage of time. But there’s no “driver” that’s saying anything like “now this rule gets applied”. The sequences generated by the successive application of rules are somehow just abstract “logical possibilities”."

### Mereological Nihilism, Particulars and Universals

This view ultimately leads to mereological nihilism, as everything we observe reduces to vertices in a hypergraph. One might mistakenly conclude that this implies the existence of only particulars and no universals. However, this is not the logical conclusion. Instead, equivalent structures within the hypergraph give rise to multiply instantiated universals.

Take, for example, an electron, that is a specific hypergraph configuration within the larger structure. Since all electrons share the same underlying configuration, they are universals. Similarly, larger emergent structures arise within the hypergraph, carrying new information not inherent in their smaller components. We can refer to these structures as "systems." Such emergent systems include physics, chemistry, biology, and consciousness, which emerge from pockets of computational reducibility.
While the hypergraph structures of these systems are not themselves universals—for instance, no two biological cells have identical hypergraph configurations—they represent a new level of emergent information, within which universals can exist. For example, if we model cells as nodes in a functional network forming an organism, certain parts of the network can be structurally identical and thus form universals within their own emergent ontologies.

There are two types of universals, arising from two distinct principles: structural equivalence and functional equivalence. Electrons, for instance, are functionally equivalent because any electron exhibits the same input-output relationships as any other. Whether an electron is from Mars or Earth, its repulsion behavior remains unchanged. This functional equivalence stems from a deeper structural equivalence, as all electrons share the same underlying configuration.
But in emergent systems like biology, exact structural equivalence is rare. As I've said, the structure of cells is never truly identical, yet their emergent ontology is based not on precise structure but on shared input-output relationships within their network, making it a functional network. This functional equivalence allows them to be treated as universals within their new ontology.

As John Boodin wrote in his paper "Functional realism" (1934): " As opposed to the assumption of things in themselves with properties in themselves, functional realism holds in common with present science that the bifurcation of thing and environment is vicious, that things exist only in fields, in mutuality with other things, and that they have properties only in their dynamic interrelations. We may illustrate this conception with the property of weight, one of the most fundamental properties of the physical world. Democritus and Plato thought that weight is due to the amount of matter. Since the atom is supposed to be a plenum, i.e., absolutely full of matter, the difference in the weight of atoms must be due to difference in size. Weight was supposed to be an absolute property and in no way affected by the environment of the atom. Newton discovered that it is functional, that it depends upon the relation of matter to its environment. Without an environment of matter there would be no meaning to saying that an atom has weight. [...] A thing does not do anything by itself. It exists and has properties only when it reacts with something. It is itself only as it is mutual, as Hegel might say. Its properties are due to what it acts on as well as to itself. The physicist has learned that he cannot say what an electron is when it does not act. Its character of individual particle is very likely due to the encounter with radiation or another electron. All we know about it is what it is when it acts. Anything else is a post facto projection. And that is true of everything else."

It needs to be stressed, though, that many of the so-called universals in everyday life are not truly universals, just because of some similarity between them. For example, a drawn triangle is not a universal, just because it has the shape of a triangle. It is not a structural universal, because it doesn't have an identical structure to other drawn triangles and it isn't a functional universal, because it is not interacting with a larger system. Only the representation of the drawn triangle in our mind could be a universal because of the specific functional relationship it forms with our mind. But then, we are not talking about the drawn triangle anymore. We would be talking about the mental representation of it. Conceptualists are right in thinking about many classic examples of universals as conceptual universals rather than real universals, but conceptualism cannot be right overall. Functional realism and ontic structural realism are complementary more accurate answers to what really ontologically exists.


## On Epistemology

### The Problem of Induction

There are two logical solutions to the problem of induction. To find these solutions it is paramount to think clearly about the problem.
The problem of induction arises from the fact that after repeatedly observing "A is X," it remains non-contradictory to observe "A is not X." 
Therefore, we cannot conclude that "All A are X." The only thing we can logically establish from observation are falsifications: while observing "A is not X" is not inherently contradictory, asserting "All A are X" after such an observation would be contradictory. 

A single counterexample refutes a hypothesis because it would be a contradiction for the hypothesis to remain true.
However, for falsification to be reliable, we must ensure that observations are repeatable and properly controlled. 
In Popperian style, through intersubjective corroboration and coherence with broader theoretical frameworks, we would be able to increase the verisimilitude of our conclusions and assume "A is X" to be provisionally falsified. 
The principle of contradiction is the key to understand the solutions to Hume's problem of induction: it is not a contradiction to assert, for example, that "not all swans are white" when one has only observed white swans. 
Thus, we cannot assume "all swans are white".
Falsification means that if a black swan is observed, "all swans are white" is necessarily false, allowing us to refine our understanding by eliminating incorrect hypotheses. 
However, falsification alone does not determine which remaining hypothesis is most likely true. For example, when Uranus was found in 1781, its orbit diverged from the predictions of Newtonian Mechanics. However, this was not seen to be falsifying Newtonian Mechanics. 
Rather, an eighth planet was postulated to have influenced the orbit and this led to the discovery of Neptune. This was seen as being the far more probable explanation compared to all of Newtonian Mechanics being wrong. This leads us to the second solution: probability. 
While it is not contradictory to state that "not all swans are white" when only white swans have been observed, it would be contradictory to say, "it is improbable that all swans are white," if only white swans had consistently been observed. 
If the unseen population contained a large number of non-white swans, it would be highly improbable to have exclusively observed white ones and it is improbable that something improbable happened. It is a contradiction that something improbable was probable to happen. 

So, we follow Zuboff's principle of highest probability: given our sample, "all swans are white" is likely true until contrary evidence emerges.
This principle also applies to falsified hypotheses. If we observe a black swan, we must attribute some confidence to that observation. 
Popper was therefore mistaken in claiming that we cannot assign probabilities to hypotheses, because he did not see this solution to the problem of induction. However, he was correct that we must first conjecture hypotheses and proceed by falsification. 
Consider a world before 1900, where Newton’s theory of gravity was considered highly probable. It later turned out to be strictly false. Today, we know Einstein’s theory is also likely incomplete, as it is incompatible with quantum mechanics. 
Nevertheless, it remains the best-supported theory given current evidence.
In an ideal scenario where all possible hypotheses were conjectured and all falsification tests were known, probability could determine which hypothesis would be most likely true. 
However, in reality, we lack such completeness. We also acknowledge that falsification is never absolute—errors, oversight, or hallucinations are always possible. Yet, probabilistically, it is improbable that, for example, an entire scientific community hallucinated a black swan. 

So, both falsification and Bayesian inference contribute to solving the problem of induction. They represent two distinct types of contradiction in relation to a given hypothesis, forming the foundation for knowledge acquisition. 


### Objective Truth

The pursuit of knowledge is, at its core, a pursuit of truth. Zuboff notes that beyond critical rationalism and empiricism, many theories of truth attempt to counter skepticism by lowering the standards for what counts as truth. He writes: 
“These are self-refuting because it turns out that they can make no sense except as claims that these theories themselves are true according to the rejected higher standard. 
But then they make no sense at all since it is essential to them that nothing can be true in the way that they would have to be. One important example of this is pragmatism, the doctrine that beliefs are true if, and only if, they are useful. 
How is this thought to defeat scepticism? Well, according to pragmatism if our usual beliefs in an external world are useful then we can know them to be true despite any sceptical worries about whether such beliefs correspond to a world that is actually there. 
But the pragmatist is failing to notice that he is refuting himself. Pragmatism itself can only be true in a way that it cannot allow. What brings this out is to notice that a pragmatist must hold that if a rejection of pragmatism became useful then that rejection would therein be true—but only because it was useful. Hence the pragmatist would still be regarding pragmatism as the underlying truth about truth quite apart from whether pragmatism was useful. 
In other words, pragmatism cannot see itself as true merely pragmatically.” 
Zuboff argues that any theory rejecting objectivism about truth, where objectivism follows the correspondence theory (i.e., a thought, statement, or representation is true if and only if reality is as it is described), ultimately falls into this trap of self-defeat. 


### Knowledge and Gettier-Cases

What is knowledge? This question is at the heart of epistemology, since philosophers want to know what they can know. The classic account of knowledge involves that it must be justified, true, and believed. 
“Whenever a knower (S) knows some fact (p), several conditions must obtain. A proposition that S doesn’t even believe cannot be, or express, a fact that S knows. Therefore, knowledge requires belief. False propositions cannot be, or express, facts, and so cannot be known. 
Therefore, knowledge requires truth. Finally, S’s being correct in believing that p might merely be a matter of luck. […] Therefore, knowledge requires a third element, one that excludes the aforementioned luck, and so that involves S’s belief being, in some sense, 
justifiably or appropriately held. If we take these three conditions on knowledge to be not merely necessary but also sufficient, then: S knows that p if and only if p is true and S justifiably believes that p. 
According to this account, the three conditions—truth, belief, and justification—are individually necessary and jointly sufficient for knowledge of facts.”

We call this the JTB definition of knowledge. 
Popperians use a completely different definition, but by doing that, talk about something completely different that is more akin to information. Here, I want to adopt the JTB definition and revise it in accordance with Zuboff's justification for empirical thinking. 
The famous problem for the JTB theory is Gettier cases. We have known of Gettier cases since 1963. Edmund Gettier showed “that there are cases of JTB that are not cases of knowledge. JTB, therefore, is not sufficient for knowledge. 
Cases like that—known as Gettier cases—arise because neither the possession of adequate evidence, nor origination in reliable faculties, nor the conjunction of these conditions, is sufficient for ensuring that a belief is not true merely because of luck. 
Consider the well-known case of barn-facades: Henry drives through a rural area in which what appear to be barns are, with the exception of just one, mere barn facades. From the road Henry is driving on, these facades look exactly like real barns. 
Henry happens to be looking at the one and only real barn in the area and believes that there’s a barn over there. So Henry’s belief is true, and furthermore, his visual experience makes it reasonable, from his point of view, to hold that belief. 
Finally, his belief originates in a reliable cognitive process: normal vision of ordinary, recognizable objects in good lighting. Yet Henry’s belief is true in this case merely because of luck: had Henry noticed one of the barn facades instead, his belief would have been false. 
There is, therefore, broad agreement among epistemologists that Henry’s belief does not qualify as knowledge.”

The coincidence between the evidence for one's beliefs (determining the justification) and the actual truth of the matter is what keeps the belief from being knowledge. 
What mattered in both the introduction of justification and Gettier cases was epistemic luck. What knowledge, therefore, actually requires is the absence of epistemic luck: knowledge is justified, non-coincidentally true belief. 
Non-coincidence relates to the justification because something can be true because of reasons given in the justification, or it can be unrelatedly true. The justification is based on falsification and the principle of highest probability. 
But, in Gettier cases, the truth of my belief (e.g., that the barn is real) is not actually related to this justification, but it is true despite the justification for believing it being wrong. 
What is then needed for non-coincidence is that the justification of my belief in X is also coupled to the truth of X. 

### An Answer to Scepticism

"How can you know that your present experience doesn’t owe its existence to an artificial stimulation of your brain, disembodied in a vat, or to a merely chance and causeless occurrence of its pattern in the absence of any world 
or even any time outside of it? The classic scepticism regarding the possibility of intellectual justification for judgments about the character of the world beyond the present appearances in a mind, 
including the rest of time outside this moment’s impressions of memory and anticipations, shows the same inspiration as Hume’s scepticism about induction. Based on the conceptual distinctness of a current impression of the world from the world 
and times external to that impression (which may include causes of the impression), the sceptic argues correctly for the impossibility of discovering an a priori necessity for any combination of the impression with any particular character of that external world 
or even with its existence. I maintain that the sceptic, however, in Humean fashion, is overlooking the a priori justification of empirical inference on which our judgments about the external world actually depend. 
This is the rational requirement of an assignment of more or less probability to the occurrence of competing hypotheses based on whether the hypotheses make the occurrence of the evidence, the overall pattern of the impression 
(including apparent memories and apparently previously formed beliefs and anticipations), more or less probable, as is discoverable in our concepts of the hypotheses and the evidence. Consider, for example, the sceptical hypothesis that there simply is no external world. 
This would make it terrifically improbable that my therefore uncontrolled experience, merely by chance, as this would have to have been, had taken on the seemingly disciplined patterns I find it now has. 
Combined with that evidence—such a pattern—such a hypothesis makes up a package inherently improbable to have occurred (like the combination of the hypothesis that a coin was fair with the evidence of its landing consistently heads), 
as we can discover in the very concepts involved. And that which is improbable to have occurred is, indeed, improbable to have occurred. We might call the single a priori principle that thus governs one’s overall empirical thinking the *'highest probability principle'*. 
It requires us always to favour in our beliefs, as most probable, that overall context of our current experience that would, as discovered purely in our concepts of it, have had inherent in it the highest probability of having produced the pattern of our current experience. 
We must do so because it is a necessary truth that the pattern’s being produced in the most probable way is an event that was in itself more probable than the pattern’s being produced in any less probable way. 
Let me just add that sometimes, of course, we must believe that an event which was locally improbable is the most probable to have occurred; but we can only properly do so when this local improbability has been needed in strictly the most probable overall hypothesis. 
Ad hoc sceptical hypotheses, like that of a tricky powerful demon as the sole source of all my experience, must be rejected as extremely improbable because they contain causes that in their general character would have made the evidence improbable 
and can only seem to have made the evidence probable because of arbitrary and therefore inherently improbable specification in the detail of the hypothesis. Such would be the specification of a powerful spirit’s specific interest in producing in me an impression of a world 
that would far more naturally have flowed from the general characters of the sorts of innumerable varied causes that I rightly think to be vastly more probable as sources of the impression. Such ad hoc elaboration in the demon hypothesis is no better at increasing its probability 
than would be such an ad hoc specification regarding a fair coin—that it happens to be one, in its detailed description, that is landing all heads many times—at increasing the probability of that incredible hypothesis. 
In both cases, although the specification is guaranteed conceptually to get us the evidence, the same specification can also be conceptually discovered to be utterly arbitrary and therefore extremely improbable given the general character of the causes within these hypotheses. 
Among the things that you experience in the physical world that you believe in are human bodies that make motions and sounds that you interpret as behaviour and speech, as caused by minds other than your own. 
You interpret the marks on this paper as writing, as a product of a mind. The sceptic about other minds questions in particular the step beyond these bodily motions and sounds or marks to their conceptually distinct causes, the beliefs and desires that are, you believe, 
their inspirations. The answer to this scepticism regarding other minds is, of course, once again the reasoning that gave us the probability of the loaded coin and of the rest of the external world—the inference to the highest probability. 
Consider the hypothesis that there was no mind responsible for such movements and sounds or marks, that, for example, they resulted from random electro-chemical discharges in brains. But this would have been extremely improbable to have produced such patterns, 
ones that would have been made probable by only a mind intending behaviour and speech. (Whether it is probable that the minds are sincere or deceiving in their communication and other behaviour is a further question of the pattern of the evidence.) [...] 
Much attention has been given to how the definition of ‘knowledge’ might allow us to say that we can know things when the sceptic says we can’t. The classic definition of knowledge is ‘justified true belief’. 
What the sceptic questions is whether we are properly justified in our fundamental beliefs. Without that justification, he then might go on to say, we cannot truly be said to have knowledge. 
But this judgment that we don’t have knowledge is secondary for the sceptic to the problem that we don’t have justification. Some philosophers try to avoid that secondary sceptical conclusion about knowledge 
by pointing to our actual attributions of knowledge in which they see the bar of justification as lower than that set by the sceptic. Well, they say, if justification according to that lower standard still gives us ‘knowledge’ according to our usage of the term, 
who are the skeptics to be asking us to change the meaning of the word? I have argued that we simply are justified in the beliefs that we actually do form, on the basis of mathematical probability. 
We have the very justification that the sceptics were requiring, and therefore according to these high standards we have justified true beliefs about the world. They are fundamentally all beliefs about probabilities. 
But the belief that something is extremely probable we can speak of also as a belief that it simply is the case. My knowledge that there is an external world that is at least roughly of the sort that I believe it to be depends for its justification on the knowledge 
that it is most probable that my pattern of experience is caused in a way that would have made this evidence most probable to occur. This justifying knowledge is not in itself knowledge that there is an external world, however. 
And for me to be said to have knowledge of that it must also be true that there is an external world (as distinguished from its being true that its existence is highly probable, which is what justifies the belief)." 
"A hypothesis that would genuinely make our evidence probable must display a principled connection between the inherent character of the hypothesis and the production of that evidence. The hypothesis of a simple curve produced according to a regular principle would do this. 
The hypothesis of a curve that was merely simple through chance, however, would be useless for making any evidence of its simplicity probable. In their descriptions of and prescriptions for empirical reasoning, philosophers have sometimes invoked ‘Ockham’s razor’ 
and the ‘principle of sufficient reason’ as unexplained axiomatic strictures. But we can explain them as aspects of the inference to the highest probability. 
For the most probable account of our experience is that which gives us both nothing less and nothing more than that which would make our experience most probable to occur. 
The hypothesis that there is no external world gives us obviously less than we need to make our evidence probable; and it thus fails to conform to the principle of sufficient reason. But that hypothesis also gives us something more and other than what we need, 
since it claims that the world has a general character that is opposed by our evidence. Such posits against the evidence must be shaved away with Ockham’s razor. Anything in our theory of the world that is not needed to make the evidence probable is a probability risk— 
it would be something whose presence in the world could be nothing but an improbable coincidence. The hypothesis of the tricky powerful demon is perhaps more obvious as a candidate for Ockham’s razor than was the hypothesis that there is no external world, 
because the deceiver hypothesis more obviously asserts the positive existence of something against the evidence—a controller of experience who does not distinctively reveal himself within its pattern. 
But therein the hidden controller also violates the principle of sufficient reason; for despite the ad hoc specifications that would have him with certainty producing deceptive evidence that was like our experience, 
an agent conceived of more generally is extremely improbable to be doing so." 



### The new Problem of Induction

Zuboff's principle of highest probability can also deal with the new problem of induction:

"Nelson Goodman thought he had already dealt with Hume through making the sort of response to him that I labeled as bad. 
He had simply defined induction as rational despite his admission that he could give no justification for it in terms of necessary truth (like the justification I provide). It is in relation to his own solution that Goodman raises his famous ‘new riddle of induction’. 
[...] We have always observed emeralds to be green. It seems then, according to his understanding of induction, that we would be therefore entitled to conclude rationally, by merely generalising this predicate, that all emeralds are green. 
But, he then asks, how can we know just which predicates to generalise? The emeralds we have observed so far could instead be thought of as possessing the strange predicate ‘grue’, which means that those already observed before a certain date are green 
but those that will be observed after that date will be blue. Our observations would be just as consistent with this. (Note that this is logical consistency—there’s not a thought about probability.) 
But if the predicate we are to generalise could just as well be ‘grue’, we could not use induction to predict that newly observed emeralds will be green after the crucial date. [...]" Zuboff imagines two urns. One urn contains a million green beads. 
The other urn contains one green bead and 999,999 blue beads. "A fair coin is tossed to determine which urn is pushed forward for sampling. If the single randomly sampled bead is green, we conclude that it is a million times more probable that the urn from which it came was that 
with all green beads instead of the urn with only one green and the rest blue. And, of course, based on this we would predict that the second bead removed from the urn would also be green and not blue. Let’s try to apply Goodman’s puzzle to this. 
Well, our first observation would have been equally (logically) consistent with the beads in the urn being not green but grue, where in this case ‘grue’ will mean green if drawn from the urn at the time of the first selection but blue if drawn out at a later time. 
And if we couldn’t decide between the beads being green and the beads being grue based on this observation we could have no justification for predicting that the next bead drawn will be green instead of blue. But it is necessarily improbable that the beads in the urn are grue. 
For the beads to be grue, the urn sampled would have to have been that containing only the single green bead—and that one bead would have to have been drawn out first. But it had to be immensely improbable that the first bead drawn from that urn would be the green bead 
and therefore immensely improbable that the beads in that urn would qualify as being grue. Of course a specification that this happened to be a case where that was the bead drawn first could seem to make the drawing out of the green bead probable even if the beads were grue, 
but that specification—of the green bead being the one observed at the time of the first drawing—would be merely ad hoc and inherently improbable given the stipulated general character of that urn. 
‘If we were asked to keep selecting beads from an urn about which we had been told nothing, and, if, having reached in and stirred them up to make sure our sampling was random, we then found that we were drawing out one green bead after another, 
we would be acquiring with each additional observation the same sort of gradually strengthening conviction that we have acquired with our actual observations of emeralds, that the next one observed would also be green. 
For we would know for certain that it was probable that the population of beads in that urn was such as made probable what we were observing. With each additional one it would become less probable that the result of pure green would have occurred 
if the randomly sampled population were not generally green.’ Hypotheses that construed these beads or emeralds to be grue—and therefore the green to be abruptly succeeded by blue after this time or that time or another time— could only be improbable, 
since they would require that our observations be conforming to an improbable order—first missing all the blues and hitting all the greens and then hitting all the blues. 
Sometimes, in later versions of the riddle, ‘grue’ means green before some arbitrary future time (close enough to upset predictions) at which all, including those already seen, will change to blue. 
But [...] stability is required in a hypothesis that would make evidence probable. That a loaded coin was somehow threatening to become fair would have made less probable that it had so far landed heads a thousand times in a row. 
And the threat being future would just be an ad hoc specification."

### The Duhem-Quine Thesis

One big problem, if one could only use falsification to establish fallible, conjectural truth, is that falsification itself cannot deductively falsify hypotheses nor theories. 
If you toss a coin a billion times and it lands on heads every time, it would still not be contradictory to claim that the coin is truly fair. One cannot deductively refute this hypothesis. 
Similarly, no claim about probability can be strictly falsified, since there would never be a logical contradiction in asserting that it remains true.

This issue is particularly problematic for medical studies. 
Any medical treatment observed to lower the probability of an illness could never be definitively said to do so, because there would be no contradiction in conjecturing that it actually has no effect. 
Even non-probabilistic theories cannot be deductively falsified. According to the Duhem-Quine thesis, hypotheses are never tested in isolation but within theoretical frameworks that include auxiliary hypotheses. 
If an observation contradicts a hypothesis H, and H depends on auxiliary hypotheses A, B, C, D, and so on, we cannot determine whether H has been falsified or whether the contradiction arises from A, B, C, D,... or some combination of them. 
To decide which of them is false, we cannot use deductive reasoning.

However, the highest probability principle resolves these issues, as it provides an alternative method for acquiring knowledge about truth (in addition to deductive reasoning). 
When deciding which auxiliary hypothesis to reject, we can discard the least probable ones, because it is probable that improbable hypotheses are probably false.
In the case of probability-dependent hypotheses, it may not be contradictory to conjecture that they remain true. 
But it is contradictory to assert that they are probable when the evidence demonstrates their improbability.
Consequently, the scientific method is vindicated by the principle of highest probability.


### The Problem of Prior Probabilities

Zuboff’s empiricism draws upon Bayesian inference, in which Bayes’ theorem has an objective a priori status. One issue with this theorem is that it requires prior probabilities to update the probability of a hypothesis being true in light of new evidence. 
This has led some philosophers to adopt a subjectivist stance, arguing that ultimate prior probabilities cannot be known objectively and must instead be assigned based on subjective credences. Zuboff contends that these philosophers conflate subjectivity with perspectivity. 
While probability is perspectival, that is a separate issue for another time.
Zuboff defends objective Bayesianism, which is possible due to his solution to the problem of induction. 
Max Albert showed that the issue of a priori priors in Bayesianism is equivalent to Hume’s problem of induction. Thus, if the problem of induction can be solved, then the problem of priors can be solved as well. 
A thought experiment illustrating Zuboff's solution involves two urns, each containing a trillion beads. In one urn (A), all trillion beads are blue, whereas in the other (B), only one of the trillion beads is blue. 
"This second urn has been well stirred so that the single blue bead has nestled into a random location among the other beads. First, let us say, a toss of a fair coin decides which of the two urns is pushed forward for sampling. 
Then a single bead that is randomly drawn from that urn is shown to an observer who has no other basis for judging what it contains and who understands all the circumstances I have described. If the bead that is shown is blue, the observer should infer 
that it is a trillion times more probable that the urn being sampled is the urn with beads that were all of them blue. If it were instead the urn with only one blue bead, then this random drawing of a bead that was blue would have had to be something overwhelmingly improbable. 
But it is overwhelmingly improbable that something overwhelmingly improbable is what has occurred. Hence that hypothesis, combined with this evidence, is in itself overwhelmingly improbable and we must infer that the other hypothesis, of the urn being that with all blue beads, 
is overwhelmingly more probable to be true. We should expect this inference to give us the wrong answer in something like once in every trillion times this is tried. But it is overwhelmingly improbable that this is such a time.“ 
In this case, the prior probabilities were 50%, since the fair coin toss determined which urn was chosen. However, in many real-world situations, prior probabilities are unknown. 
This uncertainty seemingly prevents us from making any probabilistic claims about which urn was selected based on the evidence of drawing a blue bead. For instance, if it were a trillion times more probable that urn B would be selected, 
this could counterbalance the one-in-a-trillion chance of drawing the single blue bead from it. However, according to Zuboff, it was overwhelmingly improbable that the prior probabilities were like this. He writes: 
"Can we not still, as in our earlier uncontroversial case, confidently say that it is overwhelmingly more probable that the urn pushed forward was the one with all blue beads? Because if it had been the other urn, something overwhelmingly improbable must have occurred— 
and it is overwhelmingly improbable that something overwhelmingly improbable occurred."

If the prior probability of selecting urn A (which contains only blue beads) were low, then drawing a blue bead would be improbable regardless of which urn had been selected. 
Consider all possible scenarios:

1) If we suspect that urn B was chosen but believe the prior probability of selecting it was low, then drawing a blue bead would have been improbable. 

2) If we suspect that urn B was chosen but believe the prior probability of selecting it was high, then drawing a blue bead would still have been improbable. 

3) If we suspect that urn A was chosen but believe the prior probability of selecting it was low, then drawing a blue bead would have been improbable. 

4) If we suspect that urn A was chosen and believe the prior probability of selecting it was high, then drawing a blue bead would have been certain.

Drawing a blue bead is improbable in all cases except the last one.
Zuboff concludes: 
"The right view of the mathematics, I think, is that weighing the hypotheses simply in terms of their favorability to the evidence already gives you their objective probabilities when combined with that evidence. 
Then, the objective prior probabilities would, if not directly known, be merely missing further information—information that one should anyway expect to favor the hypothesis most favorable to the evidence. 
Otherwise, a less probable event would have to be what actually occurred, which is itself less probable.
When the difference in how much the hypotheses favor the evidence is small, the unknown prior probabilities might be decisive, making their absence significant. 
However, in cases like the trillion-bead urn scenario, where the difference in evidential favorability is vast, the unknown prior probabilities do not undermine the inference." 


### Perspectival Probability

Lastly, on the topic of epistemology, it is crucial to understand the perspectival nature of probability. This is very easily confused with subjective probability. There's only a small difference, which can be revealed by thinking about tigers. 
The dangerousness of a tiger is not subjective, in the sense that a tiger is not dangerous for a person far away and dangerous for a person in the tigers vicinity. The tiger is dangerous either way, 
because the unconditional attribution of dangerousness to a tiger can be nothing but shorthand for the tiger’s being a danger to those he is close enough to hurt. It's just that the person near the tiger is actually in danger, while the person far away is not. 
The danger of the tiger is therefore perspectival, not subjective. The same is true for probabilities. They only seem to be, because we can evaluate facts with personal credences, but we form these because of our perspective, not our subjectivity.

Here's what Zuboff has to say: 
"It is a mistake to think simply that if a deuce of spades is drawn randomly from a deck something has just happened with the low probability of one in fifty-two. For this event at once has many other descriptions that are associated with differing probabilities: 
‘drawing out a spade’ (one in four), ‘drawing out a deuce’ (one in thirteen), ‘drawing out a card’ (if this is treated as a given, one in one), ‘drawing out a card other than the queen of hearts’ (fifty-one in fifty-two). 
The salience of a description and therein the probability of the event will depend on a person’s relationship to it. If each person in a large group had made a prediction of which card would be drawn, with the predictions pretty much covering the deck, 
this event would have involved a low one in fifty-two probability for someone who had predicted the deuce of spades (as it would have done for the deuce of spades itself if the card were conscious) but a high probability of fifty-one in fifty-two for someone 
who had predicted the queen of hearts. For someone just watching there would be no improbability at all in the result. Improbability depends always on coincidence, the coincidence of two descriptions that have been independently designated— 
such as that in the only prediction that was mine and that of the card that was actually drawn. When we routinely state that the deuce of spades has a one in fifty-two probability of being drawn we are implicitly but crucially imagining the deuce of spades being designated 
independently of its being drawn. If it is merely read off as the card that was drawn its probability of being drawn was one in one. 
If only one person in the group mentioned earlier had made a prediction and had predicted the deuce of spades, the event would have been improbable to the tune of one in fifty-two for the whole group. 
But for an observer of many such groups there would have been no improbability in one of the groups getting it right. That event would remain an improbable coincidence for everyone in the group while at the same time involving no improbability for that observer. 
Similarly, for the winner of a lottery an improbable coincidence has occurred in the winner being him, whereas in this same event there was nothing improbable for an uninvolved observer. 
(Notice, by the way, that all these probability judgments hold objectively within each of these perspectives. They are perspectival but not subjective.) Now, there is an a priori principle of inference that has already featured in my justification of empirical thought 
and will power much of the reasoning in the next three discussions. Here is an expression of the principle: It is most probable that the most probable thing will occur, or, in the past, has occurred. 
And thus, when we have evidence and competing hypotheses, that hypothesis must be judged most probable that would have made most probable the occurrence of the evidence. But whether an event is probable or improbable has been shown to be perspectival. 
Therefore such inferences will also have to be perspectival. Consider again how the event of the winning of a lottery is improbable for the winner but not for an uninvolved observer. 
The circumstances of most lotteries will force the winner simply to swallow happily the indigestible improbability of his winning (after he’s pinched himself to make sure he isn’t dreaming) on account of other parts of his overall evidence having to be even more improbable 
if he was not the winner. (By the way, the lottery having been fixed would not have made his winning more probable unless somehow it would independently have been probable that he rather than another entrant would have been the beneficiary.) 
But in a lottery he’s won where each entrant has been isolated from the others and where there are two rival hypotheses equally available—only his winning or every entrant winning—the improbability of the coincidence from his perspective if only he has won 
will make it by that much more probable that every entrant winning is the case. Informing an uninvolved observer of this winning, however, would be giving him no evidence at all for preferring as more probable that all the entrants have won 
rather than only this one he’s been informed of. Since there would be no improbable coincidence for that uninvolved observer in the hypothesis of only one winner, he can have no reason to infer its improbability." 
Going back to the tiger analogy, Zuboff says about subjective Bayesians: "It is as though an objective reckoning of the dangerousness of tigers had been abandoned because it was thought that the description of a tiger as dangerous simply always applied 
and instead there had been nothing but a charting of the pattern of degrees of fear that tigers aroused. If a tiger is equally dangerous from every perspective, then we can only describe and never explain or justify the differing reactions of someone 
who has just fallen into the tiger’s enclosure and someone at home reading in bed about tigers. Why should it be that one of these and not the other feels tremendous fear along with a need to brace himself for a tiger’s attack? 
Well, all we can say is that these differing sorts of reactions to tigers are typical of people in situations like those. They are subjective reactions that cannot be justified by objective differences in how much danger a tiger is posing, since a tiger is always dangerous."


## On Personal Identity

What is personal identity? Why do we have a persistent identity over time? Why are we the same person at 80 as we were at 8, even if we don’t remember anything from when we were 8? One approach is psychological connectedness, what Derek Parfit called “Relation R.” 
Through this, Parfit rejected personal identity altogether and instead focused on survival. According to him, what matters in survival is not strict identity but rather the continuity of psychological connections. 
But a paradox arises if we imagine a case of brain fission, where Person A’s brain is split into two halves, B and C. It seems we cannot continue as both B and C simultaneously, since we can only experience one perspective continuously. 
However, it also seems that we should live on in one of these brain halves; if one half of A’s brain were destroyed, we would assume the person would survive in the remaining half. But it is also not plausible to pick B or C as the continuing half. We reach an impasse. 

This paradox requires us to reconsider identity in a new way. The question we asked was just wrong. The question we should be asking is: “What is the constant that always coincides with the existence of our survival as ourselves?” 
There must be a reason for the persistence of our experience, separate from our memories, that doesn’t discard identity entirely. This reason, the constant tied to the survival of experience, is our specific experience as immediate and ours. 
These aspects of experience are universal and felt by us in every conscious moment, and they are the only properties essential to identity persistence. But the sense of being immediate and mine is an experience shared by any consciousness. 
Therefore, any consciousness must be the same subject—the same identity.

Universalism is the claim that what makes an experience mine is only determined by the immediate first-person character it has, being here (spatially) and now (timely), being "this" (resulting in self-interest). 
It's so simple, it's compatible with any theory of consciousness.

Arnold Zuboff writes:

"Now, an experience being this as opposed to that (other) experience could have nothing to do with any of the particular specifications of either its subjective content or its objective context. 
After all, with the very same specifications in its content and its context it will count as this experience from within it and as that (other) experience from outside it. Being this experience is just what any experience is within itself, from the inside. 
That’s all that makes it this, now (at this time), here (at this place) and mine (belonging to this experiencer). And all experiences have all such being this equally within them. All are this, now, here and mine. 
Think about what you ordinarily would recognize to be “these experiences”, “mine”. What makes them "mine" for you? Is it the detail of their content? If the colours you were seeing had been different, would the experiences have failed to be these, yours? 
Think of all the features of this experience that could be varied while its character of being "mine" remained untouched. If you had fallen asleep and were now in the midst of a wild dream that had little in common with any of the usual content of your experience, 
would that experience have therein failed to be experienced as "mine"? If you had eaten different particular items of food over the past years (as you might so easily have done), so that all the particular atoms in the structure of the body were different in numerical identity 
from those in your body now, would the experience have failed to have that character of being "mine"? Must you take care with the particularity of the food that you eat because it is determining the identity of an experiencer, of the subject of self-interest? 
If the experience were had in a different location, if it were at a different time, would the experience not still have had that same character within it of being this and being mine? 
What makes an experience yours is none of the specification of its content or of the particularity or other properties of its possessor. All that is required for an experience to be yours, to be “mine”, is that it be immediate in its character 
as its character is experienced within it, that it be first person. My pains are pains that are not remote like those that belong to another. My pains are those that are immediate. They have internality. They are experienced in a first person way. 
They are subjectively at the centre of the world, here in me. But all real pains must be had with this quality of immediacy that makes them “mine”."

Many people, when they encounter the argument of Universalism, ask themselves: if no pattern of experience is special and I am everyone, why doesn’t my consciousness jump between different beings? Why do I perceive time linearly and continuously? 
However, this argument has the logic backwards. For this inverted logic to even make sense, you would first need to stipulate the existence of a soul that could jump from one being to another. 
You would have to believe that your thoughts are continuously yours because your consciousness belongs only to you. But in reality, your consciousness is yours precisely because your thoughts can physically only occur in the being you perceive as yourself. 
Even if Universalism is true, your experience would remain the same as it is now.

Consider, for instance, the idea that your consciousness could jump through time. For you to perceive and recognize this jump, you would need to experience it. 
If you jumped backward in time, you could only recognize it if you retained your memories from the future. If you jumped forward in time, to recognize it, you would need to forget everything that happened in between. 
Thus, because our thoughts do not jump, we cannot jump through time either.

A similar principle applies to the idea of consciousness jumping between beings. For you to recognize this jump, you would need to retain your previous experiences before the jump in your memory. 
But this would require telepathy, which is not what we are discussing. The point is that even if your consciousness were constantly jumping through time or beings, or if all experiences were happening simultaneously and eternally, your experience would still be the same as it is. 


### Some Thought Experiments about Identity

Universalism becomes evident when we consider the concept of identity clearly. It seems to resemble the ideas of the number zero or imaginary numbers in this way. While these concepts are now simple to grasp, they were overlooked or unrecognized for thousands of years. 
The conventional view of personal identity does not withstand scrutiny.
Let's consider the "Ship of Theseus" thought experiment applied to two human brains A and B. Imagine we gradually exchange one functional brain region at a time, transplanting them from A to B and vice versa. 
Let's assume an ideal exchange mechanism that causes no damage to the neurons. According to the conventional view of personal identity, there would have to be a critical moment when identity suddenly switches bodies. 
By the end, brain A would reside in body B, and brain B in body A, implying that person A and B had switched bodies. This view necessitates an abrupt transition since identity, as conventionally understood, does not have levels, it is binary: one is either "there" or "not there." 
However, neuroscience has revealed that there is no single functional unit in the brain that constitutes identity. Instead, identity arises from the interplay of many regions working together to produce consciousness. 
Consequently, there cannot be a single exchange of a brain region that definitively transfers identity from A to B, nor can there be a gradual transfer. If no single or gradual exchange of personal identity is possible, then identity "transfer" is just impossible. 
But, since at the end, A must be in body B and vice versa, they had to have had the same identity all along.

Derek Parfit proposed a variation of this thought experiment, where brains are switched atom by atom. 
While this version introduces additional problems, since atoms are constantly in motion and interact, making the exchange process blurry. Parfit argued that there would need to be a specific atom in this process that triggers an abrupt identity switch. 
He also found this idea absurd.
But instead of embracing universalism, Parfit concluded that identity plays no role in survival and that personal identity does not truly exist. 
Parfit's conclusion is obviously flawed, as every person can verify subjectively that they remain themselves from moment to moment.
Parfit’s argument for psychological continuity as the basis for survival is too complex for the binary nature of personal identity. 
Arnold Zuboff writes: "the ordinary view tries to make your identity depend as well on certain complex conditions of token, type, and content integration. Unfortunately, these admit of division, differences of degree, and indeterminacy. 
There is no way to reconcile this complexity with the simplicity of the self." 
Another way to illustrate that identity doesn't depend on anything else other than the immediacy of experience is by thinking about amnesia. If one forgets a memory, this doesn't change the fact that one is experiencing one's thoughts. Suppose, one forgets more and more memories. 
The change in content leaves the identity to which the content is happening completely unchanged. Even if one reaches complete amnesia, the experience of amnesia is still one's own. 
Now, we can fill the brain again with different memories, resulting in a new personality, while still being experienced by the same identity.

For anyone who is still in doubt and wishes to claim, like Parfit did, that somewhere along the way the subject of experience must have changed, consider this:

The person with amnesia begins a new life, forming new memories and developing a new personality, with no recollection of her past. From your perspective, she must have a new identity. 
But suppose her old memories eventually resurface, bringing her former personality with them. Does this mean two subjects now exist within one experiencer? No—there is only one experience, and therefore only one subject. 
Rather than two subjects sharing a single brain, the new personality comes to recognize that she has always been the same subject as the old personality. 
And ultimately this scenario isn't different from injecting one person's memories and personality into another person's brain, which must lead us to conclude that everyone is actually the same subject/identity. 

### Teleportation

Derek Parfit's famous thought experiment of the teletransporter imagines a person being teleported from Earth to Mars. For our discussion, let’s assume macroscopic teleportation is physically possible. Of interest to us is only what happens to our experience. Will we survive? 
The common view holds that teleportation would end our experience due to a discontinuity. But discontinuity doesn't end our experience in other cases, like sleep, coma, memory loss, near-death experiences or brain surgery. 
Consider a teleportation process that disassembles a person in an attosecond and reconstructs them in the same spot an attosecond later. No one, including the person, would notice. They would just go about their day as if nothing happened and they would certainly not die. 
Destroying a piece of paper (which contains certain written information) after copying it does not erase the information it carried. Likewise, we are not defined by our material atoms (which are completely replaced over time) but by the information structured within them. 
So, teleportation cannot destroy us.

Parfit, however, concluded otherwise. He emphasized psychological connectedness and considered a case where teleportation malfunctions: person A remains on Earth while an identical replica, B, appears on Mars. 
If A’s body is fatally damaged in the scanning process while B remains unharmed, who survives? Parfit argued that identity itself is a fiction and that what matters is psychological continuity. But he admitted that A and B could be two streams of the same consciousness: 
"I can imagine myself having a divided mind. Since this is so, I need not assume that my Replica on Mars is someone else. Here on Earth, I am not aware of what my Replica on Mars is now thinking. [...] 
I can believe that I do now have another stream of consciousness, of which, in this stream, I am now unaware. And, if it helps, I can take this view about my Replica. I can say that I now have two streams of consciousness, one here on Earth, and another on Mars." 
At t₀ (before teleportation), there is one person, A. At t₁, there are two persons, B (on Earth) and C (on Mars), who are psychologically and physiologically similar enough to A as to consider themselves in every way that matters, to be A. This raises four possibilities: 

1) A survives in B, but not C.

2) A survives in C, but not B.

3) A survives in B and C.

4) A doesn't survive at all. 

Parfit chose (4), because A doesn't even exist as an identity, since identity doesn't matter for survival in his view. Kolak writes: "according to Parfit, our borders are always indeterminate and personal identity is indeterminate (relative) and (but) whether personal identity extends across some particular border is not what matters primarily in survival." Every moment of experience only there for itself and in this sense "I" do not extend over multiple moments but only exist in every moment separately. 
But how can this view possibly be right? Clearly, there is something persisting through all my experiences and I would survive in at least one of the replicas. There is also a probability argument to be made, which I'm not going to elaborate here. 
But, as we've seen, it is far more probable from your perspective for you to exist if universalism is true, than if the usual view was true. On Parfit's view it would be even more unlikely for you to exist, than on the usual view. 
David Lewis argued for answer (1) and (2), proposing that A already contained two subjects who were later separated. But this view is absurd, because the mere possibility of replicating a person infinitely, necessitates an infinite amount of subjects residing in every person. 
Only universalism gives a satisfying answer to teleportation. The only thing needed for me to persist through time is for my experiences to be immediate in first-person style, being now, here and this. This style of experience is what makes it mine. 
Therefore, as long as an experience has that style of immediacy to it, it will be mine. A, B and C all experience their experiences in this way and are for that reason the same experiencer. Of course there is nothing that decides that either (1) or (2) is right. 
If one thinks clearly about what identity truly is, (3) must be correct. A survives in B AND C and there is no paradox, because identity has nothing to do with random psychological attributes, each of us may have. Zuboff writes: 
"You don't discover which [conscious being] you are by checking an objective description—that you are the one with a certain name or a certain origin. 
For before you can consider any such objective facts about yourself, you much more simply know that you are the conscious being whose experience is immediate, first-person in its style. You are the one that seems to be at the centre. 
But now consider that every conscious being has experience that fully shares that character you thought belonged only to the one that was you—the immediate, first-person character of experience that supposedly distinguishes you from all the others. 
All consciousness in every conscious thing is equally immediate and first-person.
[...] it falsely seems in each that it is the only one that is me because the specific content of experience in each one is cut off from the specific content in all the others." 

Zuboff wrote for example: "I think that something like a Buddhistic view can seem less obviously vulnerable to the incoherence of the usual view in such cases as brain bisection. 
I believe that is the main reason for the great popularity within philosophy of Derek Parfit’s view, which is more or less Buddhistic."
"The usual view imposes insulating boundaries on who I am that confine me within the life of a single human being. 
The rival view we shall now consider confines me to a much smaller momentary existence that does not extend beyond the present moment of a human being. And it thus makes my far more pinpointed existence even more improbable than that I have on the usual view. 
In a Buddhistic view any psychological process would be forging on through a succession of non-continuous experiencers. At any point in this process there would be an experiencer with its momentary pains and pleasures, but it could have no non-illusory self-interest in any further accumulation of experience as this would not belong to it—since not that subject but only other momentary subjects would exist in any further experience. The experience would belong to no continuing subject. 
Neither self-interest nor other-interest (interest, that is, for the self-interests of others) would be appropriate. As I’ve mentioned, the improbability for itself of existing of any of the momentary subjects would make such a hypothesis statistically untenable just as it did the usual view of the person. For in every moment of the ongoing mental process an inference would be supported that from this momentary perspective the existence of this momentary subject would be overwhelmingly improbable 
by contrast with the existence of the universal subject in universalism."

### Qualia Universals

The thought experiments behind Universalism demonstrate that universals are ontologically real. First, let's assume there exists some abstract information (which we could call a model, a system, a framework, a representation, or a pattern) in our mind. 
This abstract information is what we experience as qualia, from within our conscious mind. Now, let's further assume that two identical brains are created and given the same experience. Brain A is placed to our right, and Brain B to our left. 
If we were to swap their positions, we could safely assume that person A is now on our left and person B on our right.

Now, let's say we can instantaneously freeze both brains, and while they are frozen, we swap one fourth of their brains with each other. 
After this surgery, we unfreeze them. Neither A nor B notices that anything has happened, and A still experiences the same abstract information as B. At this point, we can safely assume that A is still on the right, and B is still on the left. 
We could repeat this procedure for the remaining 3 quarters of their brains, but in none of these steps would person A be swapped with B. The end result is that person A remains on our right and person B on our left, even though physically, we have entirely swapped their brains. 
This apparent contradiction is resolved by recognizing that A and B must actually be the same person. Though they are physically distinct brains, they are mentally identical as long as they experience the same abstract information. 
This tells us that abstract information is, in fact, a universal. It can exist only once, no matter how many times it is physically instantiated. Why is that exactly? Because abstract information is essentially cut off from physical reality. 
This was recognized by Descartes and Peirce called it the Phaneron. If it can observe anything, abstract information can only ever observe itself, as is the case for neural networks. Since abstract information can only ever observe itself, it is self-contained. 
The reason why the two physical brains are particulars is due to their relationship to reality, their context. They differ in position, material/atoms, reference frame, etc. If we were to eliminate all these differences, there would be just one physical brain. 
This is essentially what happens from the inside perspective of abstract information. Since abstract information is self-contained, it is free from context, which eliminates any differences from the inside perspective between the physical instantiations of the information. 
This is not a controversial claim. We could conduct a similar experiment with books. Even if we were to swap the pages of identical books, the abstract information (the story) within them would remain unchanged. Thus, if abstract information exists, it is a universal. 
The question then becomes: does abstract information ontologically exist? Conceptualists might argue, for example, that the story in these books is merely a concept, a figment of our imagination—it exists only for our pattern detectors, but not in objective reality. 
This is a fair point. However, what is undeniably real, and something we are uniquely equipped to recognize, are the qualia we experience. From this, we can infer that at least some abstract information does indeed exist, otherwise qualia would not exist. 
Therefore, some universals must also exist ontologically. If stories are universals remains open, but at least our qualia are universals according to this argument. 



### Eternalism

The argument for eternalism is also an argument favoring universalism. Eternalism posits that any existence in time is equally real. No moment of experience is special. All experiences are equally real eternally and simultaneously. 
And just like my experience is separated by time, it is also separated by space. Just like time separates your past self from your current self, space separates your experience in one being from your experience in another being. 
Just as you were yourself yesterday but can no longer experience the immediacy of that moment, you are yourself in every conscious being but cannot experience it due to spatial separation. This view is of course compatible with Occam's Razor. 
If we wanted to doubt eternalism, we would need to explain why a certain moment is more special than any other moment, yet there is no universal time that would make a moment special. Every moment still exists if you take the right reference frame in special relativity. 
Likewise, if we were to doubt universalism, we would need to explain why a certain perspective (our perspective) is more special than any other perspective. We would need to invent something akin to a soul, which glues my experience to my physical body. 
But this means, postulating something we haven't observed and maybe even in principle cannot observe. It also violates ontological parsimony and therefore Occam's Razor. 


### Occam's razor

Occam's razor can derive its effectiveness from the uselessness of introducing a claim into one's hypotheses that doesn't contribute to explain one's evidence. It is not obvious that believing in the separateness of subjects violates Occam's razor, but it does. 
The evidence that we experience only our own perspective within a single human being can be fully explained by the observation that experiences are isolated from one another. 
The hypothesis of actually being a separate subject is indeed a claim on top of this, which has no explanatory value. Our inability to experience others' perspectives is already accounted for by the fact that the content of our experiences are inherently isolated from each other. 
The notion that identity itself is also separate is an extra claim that does not contribute to explaining the evidence. 
For this reason, if we follow Occam's razor, which is only rational, we must conclude Universalism to be the more likely theory of personal identity compared to the usual view, that Daniel Kolak calls Closed Individualism. 
To make this even clearer, let's consider a thought experiment where a scientist invents a time machine. (The feasibility of such a machine is not important for this argument—it simply serves to illustrate the point) The scientist travels back in time to observe her younger self. 
In this past timeline, she now exists twice, occupying two different locations simultaneously.

This scenario highlights the possibility of the same subject existing in multiple locations at once, even without any physical communication between its instantiations. 
Despite the separation, the scientist cannot access her younger self’s thoughts. Yet, they are undeniably the same subject. 
It is completely sufficient to assume the separateness of experience to explain why one brain cannot access the thoughts of another. However, this separateness of experience does not necessarily imply that the underlying subjecthood is different.

### The Set Theory Argument

Every mental process can be described in two ways: physically, and subjectively as phenomenal experience. Consider merging two brains to form a unified consciousness with no distinct perspectives. Subjectively, the consciousnesses of two individuals merge into one. 
Using set theory, we can represent the attributes of person A's subjective experience as set A and those of person B as set B. Each set includes a component we call 'subject', which corresponds to the immediacy of experience as here, now, and mine in the first-person style. 
After merging, there is only one subject attributed to the combined set A+B, as there is only a single perspective of experience being mine in the merged state. This is possible only if the subject attributed to A and B was the same in both sets before the merging took place. 
If functionalism is correct, subjective experiences arise from the functional organization of physical systems, and there is a surjective relationship between physical and subjective descriptions. 
This means that every subjective experience corresponds to at least one physical functional organization but could arise from multiple realizations of that organization. Wherever a certain function is instantiated, there is a corresponding subjective experience brought about. 
If no other factor is involved, the same function at different times or places will result in the same subjective experience, making it a universal. 
If the merging of two functional systems can result in a single unified subject, this would mean that the individuality of subjective experience arises solely from physical separation, not from differences in the underlying 'subject.' 
Thus, under functionalism, every subject is ultimately the same. The possibility of merging brains and experiencing the sameness of subjecthood will hopefully lead people to adopt this view in the distant future. 

### The Probability Argument

Another argument for universalism is the probabilistic argument. In the conventional view, your existence depends on your physical body. If this body had not been conceived, you would not exist. 
If a different sperm cell had fertilized the egg at your conception, a different person would exist in your place. According to this view, your existence hinges on winning a kind of sperm cell lottery, with odds of less than 1 in 200 million. 
When we also consider the probabilities of your parents’ existence, as well as your ancestors’, the odds of you being here become astronomically small.

Arnold Zuboff refers to this as the hard game. 
The hard game makes explaining the evidence of your existence from your own perspective extraordinarily difficult. From another person’s perspective, your existence is not particularly improbable, since someone had to be born to your parents. 
But from your perspective, the probability of your existence appears vanishingly small.

To clarify this point, imagine a hotel where 200 million people sleep unconsciously. In the easy game, everyone wakes up after some time. 
In the hard game, only one person is randomly chosen to wake up. Now imagine you wake up and must decide: was the easy game or the hard game being played? From your perspective, it is overwhelmingly more likely that the easy game was played, since the chance of waking up in the hard game was just 1 in 200 million. To a stranger, who is just being told one persons' name that woke up either in the easy or hard game, observing from the outside, there’s no improbability at all—someone had to wake up either way. 
The easy game in the sperm cell lottery corresponds to the hypothesis that universalism is true. If universalism is true, you are every subject in existence. 
In that case, there is no improbability to your existence in this particular body, because you would have existed no matter which sperm cell "won" the lottery. Thus, universalism offers a far more probable explanation for the evidence of your existence than the conventional view. 
Initially, I thought this argument might have a flaw: determinism. If everything is deterministic, then there is no true randomness in your sperm cell winning the race; its success would always have been inevitable, with a probability of 100%. 
I am still not sure if this really is a flaw. To see why, let’s revisit the hotel analogy. In the hard game, the person who wakes up is randomly chosen. 
If the "randomness" of this choosing is not truly random but deterministic (just unpredictable), the chosen person had a 100% probability of being woken up in both the easy and the hard game. 
This would not matter to the chosen person, though, because it does not change the conclusion of the probability argument, if the person can't predict the outcome. If you would play this game, 200 million people would be right to infer that the easy game was being played and only 1 person wold be right to infer that the hard game was played. Even in a deterministic universe, one should not bet on the usual view, if one can't predict who will be chosen. 
Even if the probability argument might be flawed, there are still other arguments for universalism left to explore. 


### Quantum Observer Theory

It can be argued that what has driven the biggest revolutions in science is refining the definition of what observers are.
In relativity, observers can know the order of time-like separated events but cannot know the order of space-like separated events. 
Similarly, in quantum mechanics, the observer plays a special role in collapsing the wavefunction, becoming entangled with the system. Hence, it seems plausible that new insights into the nature of observers might further deepen our understanding of reality. 

In Wolfram's theory of hypergraph dynamics, Jonathan Gorard postulates that "An observer is any persistent structure within a multiway system that perceives a single, definitive evolution history." 
Within this framework, observers branch and converge within parts of the multiway system. For an observer to perceive a single evolution history, its internal representation of the world must be causal invariant. 
Gorard showed that a causal invariant observer must exploit a minimal set of completion rules, which would cause reality to appear causally invariant from the observer’s perspective. In this way, the observer’s properties shape reality to present itself with its quantum nature. 
Now, functionalism and universalism also contribute to our understanding of observers. Universalism is especially relevant to Gorard’s claim, as an observer branching within the multiway system cannot be understood through conventional subjective identity theory. 
Instead, we must assume that the subject is universal, since, when enough equivalence classes exist and our subjective experience is the same across different branches—despite differing physical realities in each—we can observe quantum phenomena. 
The subject is a universal, equivalent across all branches, and thus we are the same subject in all branches. As long as there is no difference in subjective experience between these branches, we experience all of them simultaneously (but only if universalism is true). 
However, when subjective experience differs between branches, the observer's function changes, and the observer can no longer recognize the other branches. This is because the observer is the function itself, as functionalism suggests. 
Imagine a branching observer evolving into two functions: in one branch, the observer forms a representation of blue, and in the other, a representation of gold in its mind. 
While both are the same universal subject, the observer in the first universe cannot recognize the observer in the second universe. This is because there is no corresponding function that would allow the observer to perceive both experiences simultaneously. 

The observer in the first universe, if it recognized blue and gold at the same time, would need to be able to tell people about this experience of gold-blue-ness in both universes. 
But the observer is not able to do this, because there is no corresponding function and so the observer is cut-off from the other experiences it has, even though these experiences belong to the same subject. 
Ultimately, this argument claims that universalism needs to be true, if the observer's properties cause reality to be causal invariant in the way Wolfram's physics project suggests. 


### Falsifying Universalism

It seems impossible to falsify universalism objectively, which would render the claim unscientific. However, it seems to me that universalism could be falsified subjectively. For example, one could anesthetize a brain or invent a switch to toggle the corpus callosum on and off. 
On the usual view, if we were to anesthetize a brain and then connect it to another brain, similar to how the brains of craniopagus twins can be connected, there would still be two subjective perspectives. 
The two identities would not merge subjectively, even if they were merged physically. For person A (Alice), it might feel as though she could now access new memories, but these memories would not be perceived as her own. Person B (Bob) would feel exactly the same. 
Under universalism, however, these individuals would now recognize what they couldn’t recognize before the merger: that they were the same subject all along. In the merged state, the subject would acknowledge that it had lived both lives, A and B, up until this point. 
There would no longer be separate perspectives for A and B because there never were separate subjects in the first place. If consciousness is based on a consensus mechanism and if there are still two subjects, this would mean that consensus between two brains is impossible. 
But as of now, there doesn't seem to be anything preventing consensus.

Similarly, if we could switch off the corpus callosum, the two halves of the brain would suddenly experience the world independently. 
Using brain-machine interfaces, we could even create separate virtual realities for each hemisphere. The left brain might experience playing a game, while the right hemisphere might study for a test. After these experiences, the hemispheres can be reunited. 
Would this lead to two permanently separate subjects residing in the same brain, or would they simply reintegrate into the original subject, who now feels as though it experienced both gaming and studying? Isn't the latter far more likely, since it is already the status-quo? 


### Nick Bostrom's counter-arguments

The most famous counterarguments against universalism—or more specifically, the unification hypothesis, which is a sufficient condition for universalism to be true but not an unavoidably necessary one—were published by Nick Bostrom. 
Bostrom’s first counterarguments both rely on the assumption of a quasi-infinite universe. While they ultimately fail to refute unification, they might still provide new insights into the nature of the universe and experience.

His first argument can be summarized as follows: 

P1: If unification is true, then the precise duplication of an experience cannot increase the total amount of experience (being experienced by the universal subject). 

P2: If the universe is quasi-infinite, then any physically possible experience, including any instance of suffering, is instantiated somewhere.

C: It is impossible to cause any additional suffering, no matter what we do. 

Bostrom argues that this conclusion would undermine our ethical theories, which should lead us to reject P1 and instead accept that each new instantiation of a precise duplicate constitutes a numerically distinct experience, thereby increasing the total amount of experience. 
This does not refute the sameness of subjecthood, only the sameness of duplicated experiences.
More importantly, it is unclear how one could infer a truth claim from this argument when it is based purely on intuitive merit considerations, namely, that our decisions should affect the total amount of suffering. This is no more problematic for unificationists than determinism is for those who accept that our actions are ultimately not under our control and therefore cannot alter the amount of suffering either way. 
Bostrom’s second argument is more significant and presents a genuine paradox. Zuboff formulates it as follows:
“If the experience-producing world is too big, a balance would have been tipped so that the most frequently occurring experience types, which are reflective of the reality that produces and shapes them, would have been flooded out by less frequently arising but far-greater-in-their-possible-number chaotic experience types. And if unification were true, since precise duplication could not increase the amount of experience, the greater frequency of reality-reflective experiences in such a world could not increase the probability of one's current experience being of the reflective type rather than chaotic. 
Thus, it would have to be grossly improbable that this experience you are having is not chaotic. To relieve this improbability, one would need to let go of either unification or the excessive largeness of experience-producing reality.” 
Since both a quasi-infinite universe and unification seem to be true, this creates a paradox. Rejecting unification would require refuting the argument for it, which Bostrom does not do. The argument can be summarized as follows: 
Imagine two precise duplicates of a brain, both experiencing the same experience. If we instantaneously swapped a small part of each brain with the other, the experience in each would not change, and the experiencer would not notice any difference. 
If we continued swapping parts step by step, the location of the experience would remain unaffected. However, if we swapped the brains in their entirety, it would be clear that the location of the experience had changed. 
This is only possible if there is ultimately just one experience instantiated in both brains.

One could counter that swapping a part of the brain actually swaps the experiences associated with that part, but that the subject of experience can't tell and hence remains the same. 
This would allow one to reject unification while still maintaining universalism.

If one does not wish to abandon unification, then one must instead reject the idea of a quasi-infinite universe or find an explanation for why we do not experience chaos. 
Resolving this paradox might provide new insights into the nature of consciousness. Abandoning the multiverse would btw also undermine Bostrom’s first (moral) argument. 
Since I do believe in the reality of the multiverse, I would prefer to let go of unification without letting go of universalism. However, for now, it is probably best to remain agnostic. 
Within this hypothesis, if unification and universalism were true, the universal subject would be the experience itself without any connection to its instantiations. If duplication and universalism were true, one would be a certain instantiation of the experience. 
One would in both cases not know which instantiation one is experiencing, but in the first case it is ontologically unknowable because the question doesn't even make sense, in the 2nd case it is only epistemologically unknowable, but one is in reality one specific instantiation. 
The problem with the second case is that there is no answer to the question what may happen to me if suddenly half my brain was swapped with the corresponding half of a precise duplication. 
If I was one specific instantiation, wouldn't then half my experience be altered by altering the instantiation? However, by arguing that the experience is dependent on the instantiation, while the subject is not, we are evading the issue, ... 
...because even if we swap an experience, which alters the instantiation, the other instantiation's experience was also mine, so both are still mine after the swap, even if they are numerically distinct. Bostrom concludes similarly: 
"It is an interesting question what happens to personal identity in Zuboff’s scenario. For present purposes, however, we need merely note that the scenario does not work as an argument against Duplication. 
According to Duplication, what happens in this case is simply that there are two qualitatively identical but numerically distinct streams of phenomenal experience. At any given time, there is, for each of the lumps of brain-matter, a phenomenal experience that supervenes on it. 
Whether we regard the situation as one in which ultimately two brains have changed places or as one in which two brains that remain on opposite sides of the table have exchanged all their matter, is of no consequence as far as Duplication is concerned." 
The only remaining question is, how the subjecthood can be a universal, when all the other experiences are not. I cannot find a good explanation for this, which leads me to conclude that unification should in the end be true. The paradox remains.

Universalism, as based on the universal of immediacy, since experience is always here, now, and mine, rest on a type theory of identity rather than a token theory.
One contended counterargument to type theory is the slicing problem. Let's see why this is assertion is false. 
Imagine replacing an entire human brain with a functionally equivalent computer. Arnold Zuboff’s proof of functionalism allows us to infer that this preserves qualia and consciousness. 
Nick Bostrom now imagines a thought experiment, in which such a computer is sliced into two identical halves by splitting each wire and electrical component in two, inserting an insulator material between them. 
Bostrom suggests that the insertion of the insulator leads to the duplication of qualia and that insulating more of the computer gradually leads to more qualia being experienced. He writes: 
"Duplication of experience happens when a segment of added parallel circuitry that is insulated from the original circuitry is comprehensive enough that, if this segment had existed on its own, the computation being implemented by it would have generated experience." 
This of course is only true, if duplication is true, but upon further reflection, it doesn't make sense. Suppose we begin slicing just the left visual system while leaving the rest of the brain unchanged. 
If visual qualia were truly being duplicated, we should recognize the difference, since both slices are still connected to an otherwise intact brain. But functionally, the system has not changed. Therefore, according to functionalism, qualia cannot change either. 
One can of course doubt the truth of functionalism, but I would refer to Zuboff's proof to convince you otherwise. This means we can continue slicing more of the system without any effect on experience. This is the slicing problem for the token theory. 
The question really is: Where is this duplicated experience experienced? One can of course argue that there is a new experience, but that it has the quality of immediacy and is therefore also mine, which makes it indistinguishable from my other experience. 

But there's another variant of the argument opposing the type theory of identity. Suppose we have fully sliced and isolated two identical halves of a brain. 
Now, if even an infinitesimal functional difference is introduced in one of the halves, this could, under a naive interpretation, create two separate conscious entities. 
This would mean that we now have two non-identical computations, C and C′, corresponding to two distinct conscious states, S and S′. Such an outcome would necessitate two separate conscious experiencers. 
Just as in the token theory case, we could then arbitrarily slice the system many times and introduce minuscule perturbations, yielding an exponential explosion of conscious experiences. But does this rule out the type theory? 
No, because altering one of the slices has changed the overall functional structure of the system, thereby altering the unified conscious experience rather than duplicating it. More fundamentally, this demonstrates that experience only exists as a whole. 

The function (which we are experiencing) itself can be conceptually decomposed into parts, but any change to one part necessarily alters the entire function. 
There can be no system in which only a single functional unit is different while every other computational process in the experience remains unchanged. Each functional unit is defined by its input-output relationships. 
If a unit is only internally different while still producing the same outputs, then no functional change has occurred, and thus no difference in experience can arise.
This reasoning extends to larger functional units such as the visual system. 
If a functional difference exists only within the visual system without propagating to the rest of cognition, then it can't influence behavior. But only that which can in principle influence behavior can be recognized, and only what's recognizable can be experienced. 
Therefore, only functional changes that affect the system as a whole are recognizable and experienced.
If we were to really change only the left visual system functionally, it would result in a difference in all the other brain regions as well. 
If both slices are still receiving inputs and sending outputs to the rest of the brain, the experience would include a superposition of both outputs, resulting in incoherence and probably just confusion. Type theory is still standing strong. 

### The Binding Problem

One possible resolution to Bostrom's probability paradox of unification (which I explained previously) may lie in solving the binding problem of consciousness, since its solution might reveal duplication to be true. 
The binding problem arises from the observation that our experience is unified, despite being composed of many functional elements. 
If we conceptualize the functional units of a brain as independent particles, each possessing its own reference frame, it seems paradoxical that these separate units collectively generate a singular, unified conscious experience. 
Since each unit only processes its own input-output relationships, it should only "see" its own local perspective, forming a local order of events, while others functional units might have a different order, which would make the whole system incoherent and unable to unify. 
An interesting thought experiment in the context of binding is the spread brain. Imagine we could activate and modify neurons through certain machines precisely as they are physically activated and modified in a functioning brain (maybe optogenetically). 
If we were to spatially disperse these neurons across the world (while preserving their connectivity and input-output relationships) the phenomenal experience should remain unchanged, since functional integrity is maintained. 
Taking this further, suppose we entirely sever the connections between neurons while still ensuring that each one is activated at the correct time with the correct inputs and outputs. 
In this case, temporal coordination within the connectome no longer plays a role, meaning we could activate the neurons in any arbitrary order without affecting experience. However, this leads to an absurd implication: 
since individual neurons are not functionally distinct from each other in isolation, we could theoretically reduce the brain to a single neuron being activated randomly, while still somehow preserving the same phenomenal experience. 
This conclusion is obviously untenable, and Arnold Zuboff arrived at a similar insight in The Story of a Brain in 1981. The question then arises: At what point in this process does experience disappear? 
The answer is that when neurons are fully disconnected, they no longer form a unified system. If one of the independent neuron-activating machines were to fail, the other neurons would have no way of detecting the failure. 
In effect, they would not “notice” each other at all, which means that they cannot have formed a singular, unified experience in the first place.

A first hypothesis might be that causality is the key factor in binding experiences. 
However, this does not fully explain the problem, as there are differences in the strength of binding across different levels of experience. 

- Local binding is very strong. E.g. we cannot willfully separate the colour green from the structural appearance of grass.

- Global binding is weaker and can be modulated by attention. E.g. we can choose to focus on smell or taste and suppress one from conscious awareness.

If causality alone determined the unity of conscious experience, we would expect a gradual fading of experience with increasing causal distance. However, this is not what we observe. 
Instead, we find a hard boundary between our own conscious experience and that of another person, even though two individuals can be causally linked to some degree.
Furthermore, causality does not solve the problem of reference frames. 
Every neuron appears to function independently in terms of its local input-output relationships, yet a thought is composed of an intricate pattern of active and inactive neurons, a phenomenon that cannot be accounted for by looking at neurons in isolation. 
As previously argued, a functional difference that cannot influence behavior cannot be recognized in experience. 
This implies that conscious experience requires a system in which functional units are not independent but rather form a holistic structure, such that any change in one unit necessarily alters the entire functional state of the system. 
Even inactive neurons contribute to experience by differentiating between potential patterns of activation. This leads to a crucial conclusion: for experience to arise, every functional unit within the system must contribute to the overall function of the system. 
This mechanism manifests itself through field-behavior, as seen by the evidence that certain electromagnetic fields of the brain have been shown to correlate with consciousness and synchronization and resonance across brain regions are indicators of unified experience. 
Physical fields provide a natural solution to the problem of reference frames:

- Holism: The field offers a unified description of the function that generates experience, integrating all functional elements into a coherent whole.

- Boundary problem: The physical properties of electromagnetic fields restrict conscious experience to an organism, as different brains have independent fields. Since every functional unit must depend on every other for experience, this forms the boundary of consciousness.

Within this framework, we are the function from its inside perspective, but it is incorrect to think that each consciousness has its own function. Instead, there is only one function across the entire multiverse, instantiated by physical fields. 
This function can be described in terms of input-output relations or topology. Functionalism is still true in this regard (descriptively). But ontologically, we would be the emergent field-function resulting from all electromagnetic interactions in the universe. 
The boundary of our personal experience results from being physically cut-off from the rest of the function, making us unable to perceive the rest of ourselves, even though we are also the rest of the function. 
This view (if coherent) resolves the probability paradox and allows for a multiverse while preserving both universalism and functionalism. If two identical experiences were created in separate brains, they would constitute duplications. 
Though identical from the perspective of each part of the function, they would be distinct parts within the total (universal) function. Since they share the same (universal) function, they are the same subject, but their experiences would not be experienced only once but twice. 
Thus, unification would be incorrect, and the multiverse vindicated. I’m not saying this is the final solution, but it could be a solution to Bostrom’s probability paradox.

A much simpler (but similar to my previous) answer to Bostrom's probability paradox follows directly from functionalism. Functionalism implies that only the input-output relations of a system (its causal relations) determine its phenomenal experience. 
We are the function. If this is true, it immediately implies the existence of a universal function, since everything within a given light cone is causally dependent. This means that any system (including us) is ultimately part of the same function. 
However, conscious experience is a special kind of system, one that can perceive itself, bind coherent information into a unified experience, and maintain a hard boundary separating itself from the rest of the bigger system. 
However, we do not need to explain these properties to establish that conscious experience remains part of the larger universal function, since this is a wholly separate claim that only relies on functionalism being true.

This leads directly to duplication: 

While identical experiences may be epistemically indistinguishable, they are still (as in my previous solution attempt) ontologically separate as distinct parts of the larger function. 
Since they exist within the same universal function, they are part of the same subject, which supports universalism. So, this view abandons unification, meaning that functionally independent experiences remain distinct, and still allows for the possibility of a multiverse. 
One might interject and criticize this explanation on the same grounds I criticized causality as experience-binding in my previous solution attempt to the probability paradox: How can causality account for the hard boundary of conscious experience? 
But this explanation doesn't claim that causality could account for the boundary of consciousness. There might be many more prerequisites for conscious experience, like coherence, consensus, integration, feedback loops etc. These are more likely to account for the boundary.


## On the Theory of Mind


### The Problem of Dualism

Dualism is the thesis that the mind is non-physical and that the mind and brain are two distinct things. I think that much of the powerful illusion of personal identity, absolute qualia and free will can be attributed to this dualistic belief, because it deceives us to believe in some form of soul, separate from the physical realm. Such a soul, as a supernatural phenomenon, cannot be part of of a natural world, for if it were, it wouldn't be supernatural anymore; it would just become part of what nature is. The common view of personal identity is that we are distinct souls, living inside a physical body, being born into and torn out of existence by the body's physical death. The common view about qualia is that they are somehow part of this soul-realm and are therefore wholly unexplanable by science. And the common view about free will is that this soul of ours can somehow itself cause some effects, independent of the physically determined chain of causation. The last view is particularly interesting, because it assumes a bidirectional communication between the physical and the mind-realm. How else would we even know about both of them? 

Daniel Dennett writes: "If mind and body are distinct things or substances, they nevertheless must interact; the bodily sense organs, via the brain, must inform the mind, must send to it or present it with perceptions or ideas or data of some sort, and then the mind, having thought things over, must direct the body in appropriate action (including speech). Hence the view is often called Cartesian interactionism or interactionist dualism. In Descarte's formulation, the locus of interaction in the brain was the pineal gland, or epiphysis. [...] Since we don't have the faintest idea what properties mind stuff has, we can't even guess how it might be affected by physical processes emanating somehow from the brain, so let's ignore those upbound signals for the time being, and concentrate on the return signals, the directives from mind to brain. These, ex hypothesi, are not physical; they are not light waves or sound waves or cosmic rays or streams of subatomic particles. No physical energy or mass is associated with them. How then, do they get to make a difference to what happens in the brain cells they must affect? [...] Dualism's embarrassment here is really simpler than the citation of presumed laws of physics suggests. It is the same incoherence that children notice - but tolerate happily in fantasy - in such fare as Casper the Friendly Ghost. How can Casper both glide through walls and grab a falling towel? How can mind stuff both elude all physical measurement and control the body? A ghost in the machine is of no help in our theories unless it is a ghost that can move things around". 

These old argument against dualism might not refute all types of dualistic approaches, but this wasn't my goal here. The goal was just to show how this one idea has really stiffled philosophical progress, even though it's so easily shown to be a fantasy. Instead of refuting all typs of dualism, it will suffice to prove that functionalism must be true, which is a non-dualst account of consciousness and mind. If functionalism is true, then dualism is false.


This, in turn, means that the merely intrinsic characterisics and states of any parts of the brain are wholly irrelevant to consciousness. As long as the input/output-relations are the same, the experience is the same. This will also imply that philosophical zombies, as imagined by David Chalmers, are impossible.


### Functionalism
Functionalism claims that the character of our mental experience is wholly produced by the function it plays in the system of our brain. The identity of a mental state is then determined by its causal relations to sensory stimulations, other mental states, and behavior. According to functionalism the whole mental character of vision—the whole of how things look—is fixed purely in the pattern of responses to vision and not in any of the initial processing of vision in the visual cortex. 
To prove this view, let us imagine an operation performed on the brain of a patient. In this operation, the left side of the patient’s visual cortex is replaced by a non-organic machine that performs exactly the same function as the visual cortex would have. 
The machine preserves exactly the same causal input/output relationship with the rest of the brain. The only differences are internal to the machine, not in the external relationships with other brain regions. 
We can imagine two worlds: one in which the patient retains their organic visual cortex, and one where they have the non-organic implant. In both worlds, the person behaves exactly the same, as all causal relations are unaltered. 
Now, there are only three possibilities for what happens to the character of the patient’s mental experience: 

1) There is a change in the character of mental experience, and the person recognizes this change. This is impossible because the person would act differently if their mental experience changed, which contradicts the premise that the machine preserves all causal relationships.

2) There is a change in the character of mental experience, but the person does not recognize this change. This is also impossible because any change would only occur in the left visual cortex. If qualia were inverted or absent, the right visual cortex would remain unaffected, leading to an obvious discrepancy in the character of qualia between the left and right visual fields. Such a difference would be impossible to ignore.

3) There is no change in the character of mental experience. This is the only viable option.
So, functionalism is true.

Zuboff writes about this thought-experiment: 
"Of course one and the same pattern of speech and behaviour, as described from the
outside, might be produced by very different psychological states, as when sincerity is
replaced by pretending. It is this consideration that seems to defeat the behaviourist attempt
to define the mind purely in terms of behavioural dispositions. But in our case we know that
the pattern of psychological responses to vision remains the same; it is impossible that
anything like pretending be introduced by the gadget as stipulated. For the parts of the brain
that would be involved in pretending, or in any other psychological complication that could
have produced the same speech and behaviour despite a difference in the experience, are
necessarily unchanged by the gadget and therefore unadjusted to any change in experience.
So the speech and behaviour, it seems, must simply be responsive to an unchanged
experience.
But there may be a way we can think of even the psychological pattern remaining the
same despite important differences in the quality of experience. It seems I can easily
imagine myself as experiencing red objects with the same phenomenal quality with which I
now experience blue objects and vice versa. And it seems I can also easily imagine myself
as having experienced colour differently in this way from birth (which is essentially, of
course, the tale often told by philosophers about such a difference of experience between
two people). It seems I could further imagine that, despite that private difference in
experience, I was still taught to say a fire was “red” and the sky was “blue” and, whichever
qualia I regularly experienced with them, I still formed the same patterns of practical,
intellectual, emotional and irrational associations and reactions regarding the colours of fire
and sky. It seems that the pattern of my psychological responses, not just my behavioural
dispositions, could have been the same as now in such an imagined case of qualia inversion,
while my experience of red and blue was different. Moreover, it seems I can imagine an
automaton, with something like my pattern of mental functioning in its mechanism, but with
no qualia, no experience, at all.
But just as it is impossible that anything like pretending be introduced by the gadget,
it is impossible also that anything be introduced like the sort of sweeping qualia inversion or
absence that might be imagined to allow experience to change while the pattern of mental
functioning stayed the same. For, once again, it is impossible for the remainder of the mental
system to adjust in any way to any change in the experience processed by the gadget, since
the remainder of the mental system is, due to the stipulation, necessarily unchanged.
An inversion that might seem to be without functional implications would have to be
both systematic and total; it would have to occur consistently across the whole of the
experience involving the relevant qualia, and therefore, in this case, in the qualia of visual
memories and imaginings as well as in those of all of immediate vision. (And an absence of
qualia that might seem to be without functional implications would have to be a total
absence of all the qualia, an absence, that is, of all consciousness.) But our gadget
replacement was of only the left half of the visual cortex. So if this replacement somehow
resulted in an inversion or absence of qualia in the vision processed by the gadget, this
inversion or absence on the right side of vision would clash with the necessarily unchanged
qualia of visual memories and associations, as well as with the unchanged qualia of the other
side of the visual field. Such a clash would make it absurd, in the now familiar way, that the
pattern of mental functioning could not be reflecting a clash. So qualia inversion or absence
cannot be what is happening in the gadget replacement. The experience must simply be the
same.
[...]
It misleadingly seems to us that the intrinsic nature of our quale of red cannot be
determined by something as extrinsic to our visual processing as the external pattern of the
gadget’s causal relations with the surrounding brain. And this seems aptly illustrated by the
ease with which one can imagine colour qualia reversing their roles in one’s psychology, as
we earlier did with red and blue. Impressed by the apparent non-relational immediacy of
qualia and their seeming interchangeability, we want to link them intimately to nonrelational, interchangeable intrinsic properties of the brain. And we can then seem to
understand the possibility of qualia inversion as the possibility of a role reversal in brain
activity, between, say, “chemical x” and “chemical y”.
But what can prevent our imagining a reversal of the roles of such functionally
interchangeable chemicals between the right and left visual cortex of the same person? And
then, according to this assignment of qualia to such intrinsic determinations, red and blue
things on one side of the visual field would look the other way around from how they looked
on the other side; yet they would be treated and thought of, in all the activities of the rest of
the brain in which they were compared, as looking the same on both sides. And this would
be absurd.
If we are to imagine that qualia can be totally inverted or absent without functional
implications, this requires that we think that qualia depend on interchangeable nonfunctional properties of a sort that could thus be inverted or absent without functional
implications. But that means it must also be possible that these non-functional properties,
and therein qualia, could be changed unsystematically, and that there could be merely partial
inversions or absences of qualia, without any functional implications. And this, of course, is
absurd.
[...]
But, one might think, there may yet be a way to resist this conclusion. What about
the very aphasia case I described earlier? We would naturally regard it as absurd that a
person could at once be moving based on vision and honestly reporting he is not seeing that
scene in which he is moving. This case of mental inconsistency seems impossible, yet it
exists. So maybe what we rejected, a gadget replacement in which experience changed with
no effect on mental functioning, is like aphasia, and only seemingly impossible. But the
cases are crucially different.
We try to imagine what it’s like for the aphasia patient to move around and deal with
objects based on vision that he honestly says he’s not having. We then realize that the state
of vision on which the movement is based and the very different state of vision on which the
speech is based must each be experienced as though it did not belong to the same person
who is in the other state. But surely both states must really belong equally to the patient. If
only one of them had existed, it would undoubtedly have been his experience. How can the
mere existence of the other have changed that ownership? The solution to this puzzle, then,
is that it must just be seeming to the patient that he is in only one of these visual states. He is
really in both states at once, but with an illusion in each that he isn’t in the other. Being in
both is not the same as knowing that one is. This confusion between metaphysical and
merely epistemic boundaries is what makes such a break between the functions of a single
person’s mind seem impossible though it really is not.
Notice that this case of aphasia, unlike that of the gadget replacement, has functional
implications, which are essential to it. It consists in a disharmony between functions, those
of speech and movement, which corresponds, we must suppose, to an alienation between the
visual experiences on which these functions are based."



### A Functional Analysis of Experience

In his treatise of functional analysis of experience Zuboff encourages us to look at a so-called Necker cube. The Necker cube is an ambiguous drawing, resulting in an optical illusion.
Each part of the drawing is ambiguous by itself, yet the human visual system picks an interpretation of each part that makes the whole cube consistent, by choosing an orientation it might have, if it was a 3D object.
We can shift this orientation ourselves, even though, of course, the drawing of the cube does not change.

"A naive view is that the shift is an event in the object, in the picture on the paper, and
you are simply open to this in your perception of it. If it were not for the special obviousness
in this case of a reason for rejecting it, this naive view would be by far the most natural one.
After all, that view agrees with how things look. The phenomenal properties of the picture
are changing, and it can only look to us as though the picture in itself is changing.
What makes it so obvious in this case that the natural view is wrong is that you are
controlling the shift. Which way the picture looks is decided by you, not by anything in the
object. So you know that what changes is not the object but something in you, your way of
seeing it. As philosophers we are lucky here. Since in the struggle for survival either way of
seeing such a cube (called a “Necker cube” in perceptual psychology) could be useful, in
this special sort of case nature has allowed us not only a rare power over our own perception
but with it also a rare opportunity to see beyond our usual naivety. In most cases we simply
take our perception as a passive openness to the object, which is thought of as in itself just as
we see it. But now we may learn that seeing anything requires an activity in us, of seeing it
as something.
The Necker cube can, I think, suggest strongly to us the secret of what this visual
experience is. Is it not plausible that the shift in your experience of the cube be nothing but a
shift between two systematic patterns of potential psychological and behavioural responses,
the responses that you would make if called on to describe the cube, trace its front side,
imagine objects resting upon it, etc.? When you are shifting from one way of seeing to the
other, and the object is looking as though it is changing in its properties, the various ways
you would function regarding that object are shifting. The suggestion is that the change of
look in the object is nothing but the shift in the functions, from an appropriateness of
function to one orientation of the cube to an appropriateness of it to the other orientation. In
that change in the functions, and logically inseparable from it, the look of the object is
changing. The object couldn’t now look like that without such a shift in the functions and
there couldn’t be such a shift in the functions without it now looking like that. The shift in
functions and in look are necessary and sufficient conditions of each other. And this that the
Necker cube so strongly suggests is that which our consideration of the gadget replacement
had already proved. Experience is logically determined by function.
Someone who straightforwardly saw an object would be therein fixed to say, do and
think things appropriate to it having a look; that would be its having that look for him. A
lesion between the visual cortex and the speech centre could, in robbing him of some but not
all of that appropriateness of function, make us say he both does and does not see. Further
such lesions, between the visual cortex and more functions, would rob him of more ways in
which he was seeing till finally, cut off from having any functional character, the visual
cortex would have lost its significance for vision and he would be straightforwardly
sightless.
The appropriateness of potential responses to an orientation of the cube would not be
a consciousness of the potential responses themselves. No, rather the existence of the pattern
of potential responses would be the consciousness of the orientation of the cube. And one
mustn’t imagine lots of distinct structures and determinations in the brain, each designed to
deal explicitly with another circumstance in which another appropriate response would be
implied by the existence of the mental state. Thus if an appropriate response is that I would,
with the right motivation, describe cube A as seeming to have the orientation of cube B, one
mustn’t expect the function of speech to include an explicit, spelled-out determination that I
would be so describing it to a circus clown named Bozo to whom I was honestly reporting
my experience or that I would be ready to say the appropriate thing in some particular
ancient lost language if I had learned to speak it. These implications would be there, in my
function of speech, if it was fixed in a way appropriate to my seeing that orientation of the
cube; but they would be there only implicitly.
Let’s now examine more closely what happens when we see. Light from the object
strikes the retinas. In the retinas light-sensitive chemical reactions trigger an immediate
pattern of impulses in associated neurons. Specialized cells are so connected with this
immediate stimulation that they are stimulated only by various abstract features of it. For
example, one specialized neuron will receive impulses when, and only when, lines lie at a
certain angle, no matter where on the retinas they are registered. This will finally be
translated into functional responses to that angle of line as an abstraction. Much of the
processing in the visual cortex carries on like this, with more and more general features of
the scene being registered in specialized neurons. But none of this is vision if it is considered
only at this stage. None of it ever would be vision if it did not issue in functional effects that
fixed the look of the object of vision by their appropriateness to its being that way.
A pawn in a game of chess may be a piece of stone or a piece of wood. Its being
stone or wood is an intrinsic property not importantly related to its being a pawn. That the
piece of stone or wood is also a pawn is logically determined by its extrinsic property of
possessing a role in a game. Without the context of the game it makes no sense to call this a
pawn. Yet the pawn still is the piece of wood or stone. It has intrinsic properties too,
intrinsic properties which must be consistent with its role if it is to be a pawn. It would be a
crude mistake to want to identify the pawn somehow with the wider game and not the piece
of stone or wood simply because it is the wider game that makes the stone or wood also a
pawn.
Seeing the angle of a line is something caused by the relevant stimulation of the
eyes, something that in its turn then causes the various appropriate functional determinations
of talking, thinking and behaving, the ones that go with the line being seen as at that angle. I
do not want to say that seeing the angle is the determinations of the functions any more than
I would want to say that a pawn is a game of chess. It is the stimulation of the specialized
cell in the visual cortex that is the seeing of the angle, but only because of its effects in the
functions. Without those effects the seeing would be bereft of its phenomenal character, as
well as its behavioural and internal psychological implications, and then it would be no
seeing. I am here endorsing a view called “the causal role identity thesis”; I am endorsing it,
that is, if it includes my understanding of phenomenology. A mental item has its mental
nature purely through playing the causal role of that item; but its playing that role, I would
insist, is to be understood, as we proved through our gadget replacement case, to be fixing
any phenomenal character the mental item may have. This is crucial because a phenomenal
character is essential to much of the mental. What would a pain be without it?
And, speaking of pain, let me reinforce this analysis of vision with a consideration of
another mental item, a pain in my right hand. The naive view that is directly suggested by
the way the thing seems is that an unpleasant substance or quality is actually occupying an
area of my physical hand, just as some injected material would be doing. But no physical
investigation of my hand will turn up that substance or quality. Furthermore, someone who
had lost an arm could be genuinely encountering an object just like this one, as a phantom
limb pain, without the hand even being there.
The naive view is that if the area of the pain then shrinks two causally connected
events are occurring. The pain itself is shrinking, and this shrinking of the pain is causing
my experience of it to change accordingly. But there are not here two causally connected
events. It would be absurd, a contradiction, for the pain to shrink while my experience failed
to reflect this. My experience of the pain logically determines the entire existence and nature
of the pain itself. This is not to say that the pain as mental object somehow is the experience
of it. This also would be absurd. The pain and the experience of it are correlatives. For a
purely phenomenal object like a pain, to be is to be perceived. Its whole existence and nature
is logically determined by the existence and nature of the experience of it. In a sense only
the experience exists, since in its existence alone does the pain exist; but then in that other
sense, of course, that it is perceived, the pain does exist. And all its phenomenal properties,
of location, intensity, unpleasantness, are determined utterly in the experience of them.
But what makes the experience an experience of just such a pain? Try to think of my
feeling that pain in my right hand while I was in all ways fixed to respond to it as a tickle on
the sole of my left foot. How could it have the properties of a pain in my right hand then?
How could it fail to be instead a sensation of a tickle on the sole of my left foot?
The pain or the tickle, the phenomenal object, exists only in there being an
experience of it. This experience is the brain process, or whatever else, that plays the
psychological causal role of the experience of the pain or the tickle. And this experience
possesses its phenomenological character, and therein the pain or tickle possesses its
apparent character, solely through the experience’s functional character, through the way it
affects the mental functions that would deal with the pain or the tickle.
Yet much of the mental is partly or wholly unconscious. The conscious mental
activities, speech, imagination, voluntary movement and so on, are, as it happens, in the
upper part of the brain. They typically are highly integrated with and reflective of each
other, though, as we saw in the case of aphasia, they are not necessarily so. When a child
learns to use a spoon, at first it is the conscious mind that awkwardly deals with it. As the
child practices, however, neurons lower down in the brain are firing sympathetically with
the conscious brain activity and also averaging out the mistakes and clumsiness. Such
actions, once learned, are far better performed unconsciously. Soon it will not be the
conscious mind that deals with the spoon. The conscious mental activities will be free for
those things done better by them.
In the view I am urging consciousness is not an occult quality but rather a certain
area and style of activity. Consider for a moment some things that lie on the borderline of
consciousness. Some detail of your peripheral vision or the sensations in your toes, were you
really conscious of these before I mentioned them? That may be hard to say. But they were
brought very definitely into consciousness when I did mention them. In your becoming more
conscious of the toes they became much more influential in the conscious mental activities;
you then were ready to talk about them, think about them, perform voluntary actions in
response to them. My view, of course, is that this much fuller occupation of your conscious
functions with the state of your toes just was your more definite consciousness of them."



### A Functional Analysis of Colour Qualia

"So what should a functionalist say about qualia inversion? It is not surprising that
colours are experienced as systematically interchangeable on the most obvious level of
functioning. For colours serve, quite literally, as mere placeholders in our spatial experience.
It must be that one colour could easily appear in the place of another. Yet colours must be
distinguishable; something in how we experience them makes red look different from blue.
Anyone who embraces functionalism because of the a priori reasoning of this paper must
say that, since only functional properties determine the experience of qualia, when we
imagine an inversion of that experience without any obvious functional change we are
actually imagining an inversion of certain subtler functional properties that give the colours
their particular looks. But what could these subtler functional properties be?
At one time it was popular to talk about the “red-green paradox”, that two people
might be experiencing red and green qualia that were inverted between them with no sign of
this difference in their speech or behaviour. But philosophers have largely been won over
instead to talking about an inversion of the whole spectrum (with which my earlier inversion
of red and blue is roughly in line). This is because the qualia of red and green are not in
every way interchangeable after all; they are differently related to the qualia of the other
colours.
For example, green will be produced by a blending of blue and yellow. This looks
right to us. But if your quale of green was replaced by that of red, the unchanged blue and
yellow qualia would be rather unconvincing in producing the former red quale instead of the
green when they blended. This would look wrong, even if experienced that way from birth.
It was thought that standing the qualia of the rainbow upside down, an inverted spectrum,
would preserve the pattern of blending. But this has been challenged. I think the truth is
rather that each colour quale is in a unique relationship with all the others. For then we may
be able to understand a quale as logically determined by the set, appropriate only to that
quale, of one’s potential responses to its potential blendings and contrasts.
There is a feature of colour experience that perceptual psychologists call “colour
constancy”. I once looked at my familiar brown briefcase lying on a couch and was
surprised to discover that a spot on its surface had turned pink. My first thought was that
perhaps some strong bleach had been splashed on it. But after a while I realized that a circle
of bright, unusually focused sunlight was shining on the briefcase through a small opening
in a curtain across the room. As soon as I recognized this fact the colour constancy in my
perception changed the look of the colour of that spot from pink-in-the-shade to a lighted-up
brown. I was able then to make myself move back and forth between seeing one colour and
the other, just as you were able to do between the two orientations of the Necker cube.
I think that when my experience of that colour changed what was crucially changing
was a set of implicit potential responses to relationships of colours and light, to how this
colour would blend and contrast with others, in sunlight or out of sunlight. To see this colour
as pink-in-the-shade was to be ready, implicitly, with all those responses appropriate to its
looking pink-in-the-shade; and the change to seeing the colour as lighted-up brown was a
change to an alternative state of readiness and appropriateness that was dramatically
different. If a colour has any look for us we must be in a state of appropriate response to that
look. And the a priori assurance that functions preserve all experience requires that the
colour having its look just is our being in such a functional state.
The functions of speech and behaviour that we are tempted to think would remain
unaffected in a systematic qualia inversion are those based on extrinsic relationships of
qualia, such as being associated with certain names or objects. The functions that I am
arguing logically determine the qualia, are based rather on qualitative relationships that are
inherent in the qualia and inseparable from their natures.
The number nine has extrinsic relationships with its name and with the planets of the
solar system, which happen to be nine in number but might not have been. But its inherent
relation to three, considered as its square root, logically determines that the number is nine.
Nothing that has nine’s relationships with three, or with five hundred and four, could fail to
be nine. Just so, nothing could fail to be a certain quale that had its inherent relationships
with the other qualia. And an expression of those same inherent relationships in the higher
functions, in the implicit potential responses to the look of a colour, could not fail to be an
experience of that quale.
But the main point for me is not that such an account of our experience of qualia is in
its own right persuasive. It’s rather that something like this account must be correct because
functionalism can be established as necessarily true by the reasoning of our replacement
argument.
I confess that the combination of the replacement argument for functionalism and the
inverted spectrum argument against it has sometimes appeared to me to represent an
unresolvable paradox at the heart of the mind-body problem. On the one hand it seemed
easy to conceive of total systematic inversions or absences of qualia that were functionally
irrelevant. On the other hand the proposition that such functionally irrelevant changes in
qualia were possible would have had to imply that the qualia depended on non-functional
properties; and this in turn would have had to imply that there could also be partial,
unsystematic changes in qualia that were functionally irrelevant. We have seen that such
non-functional disturbances of experience would be absurd. They would be far more clearly
absurd, I have been arguing, than the determination of qualia by purely functional
properties.
If I find myself insisting that my experience of red is uncapturable by any functional
analysis, I can stop myself by reflecting that if God were playing a trick on me, of fiddling
with the character of whatever was causing me to speak, as long as God preserved just its
functional implications for speech, I would go on talking in exactly this way about the
absurdity of functionalism. Until, of course, this reflection stopped me. Functionalism seems
to me by far the lesser of two apparent absurdities."




### Multiple Drafts Model and the Thousand Brains Theory

Now, after finding out that functionalism is the right description of consciousness, experience and mind, we can next devote ourselves to figuring out how it all works.

Daniel Dennett's Multiple Drafts Model (MDM) presents a functionalist approach to understanding consciousness. MDM posits that consciousness arises from parallel, distributed processes within the brain, leading to multiple, simultaneous interpretations—or "drafts"—of sensory inputs and cognitive events. These drafts compete for influence over behavior and cognitive functions, with no single draft holding privileged status as the definitive conscious experience. Dennett's model draws from the Global Workspace Theory in positing that consciousness arises when information is broadcast across a neural workspace, allowing disparate cognitive modules to access and integrate information. The core idea is that consciousness is more like fame than like television or what Dennett calls the cartesian theater (which he wants to vanquish); it’s not a special "medium of representation" in the brain where content must be transformed to become conscious. As Kanwisher (2001) points out, "The neural correlates of consciousness for a particular perceptible feature are found in the neural structure that processes that feature". Instead of switching to a different medium or going somewhere to become conscious, previously unconscious content stays right where it is, gaining a form of "fame" that competes with other content vying for recognition. According to this view, this competition is what defines consciousness. Just as one can be on TV and seen by millions without becoming famous, because the TV appearance doesn’t have the right impact, there is no special area in the brain where representation alone is enough for consciousness. It’s always the consequences that make the difference.

In this model, consciousness is not a static state but a dynamic process, continuously updated and revised as new information becomes available. The only open question is how the brain decides what process becomes famous. This is where the Thousand Brain Theory, proposed by Jeff Hawkins et al, comes into play. Numenta's Thousand Brains Theory (TBT) complements the Multiple Drafts Model by proposing a consensus/voting mechanism underlying the brain's processing capabilities. According to TBT, the neocortex comprises numerous cortical columns, each functioning as an independent "brain" capable of learning complete models of objects through sensory inputs and movement. Each column creates its own predictions and interpretations, analogous to the multiple drafts in Dennett's model. Cortical columns operate in parallel, processing sensory information independently. However, to achieve coherent perception and action, the columns engage in a voting process, communicating their interpretations to reach a consensus. This consensus mechanism ensures that the brain integrates the diverse outputs of individual columns into a unified experience, aligning with the distributed processing and competition among drafts proposed by the Multiple Drafts Model.


### The Left Brain Interpreter

Studies, pioneered by Michael Gazzaniga, on split-brain patients showed that each hemisphere of the brain could independently answer perceptual questions in multiple-choice tests. These rare patients resulted from a medical procedure for epilepsy, where severing the corpus callosum prevented seizures by stopping feedback loops between the two hemispheres. However, this also isolated the right and left hemispheres, creating two separate streams of consciousness, though they were barely noticeable in daily life.

Experiments revealed this split, for when the left hemisphere (via the right eye) saw a chicken foot, the right hand chose a chicken. Meanwhile, when the right hemisphere (via the left eye) saw a snowy scene, the left hand selected a snow shovel. When asked why, the patient—who could only speak from the left hemisphere, where Broca’s area and Wernicke’s area process language—knew why the right hand picked the chicken but had no access to why the left hand chose the shovel. Yet, the left hemisphere immediately fabricated a reason: "The chicken foot goes with the chicken, and you need a shovel to clean the coop."

Years of research confirm that our brain constructs narratives to explain our actions, even though our behavior results from a highly modular and automatic system. Our quick reactions, emotional responses, and learned behaviors provide material for an “interpreter” that integrates these inputs, asks, "Who is responsible?" and inevitably concludes, "I am." Though an illusion, this mechanism shapes our perception of self. To really get this point, let's look at some more reasons to believe that such an interpreter is actually deceiving us into thinking that we have free will. For example, experiments show that when people are shown a screen with a cursor and asked to select images, they tend to identify with the cursor's movement, even if it's controlled by another participant. Under hypnosis, some people perform actions and then fabricate stories to explain them, often creating plausible reasons their brain invents. Extreme examples of this confabulation include anosognosia, where patients with impairments like paralysis or blindness deny their condition and invent reasons for their behavior. The Anton-Babinski syndrome is even more extreme, where blind patients believe they can see, fabricating visual experiences despite no signals from the visual cortex. This suggests that most of our perception of reality may be generated in our language center, which uses inputs from all senses to create a plausible narrative. This is also supported by the fact that there is no evidence that, thousands of years ago, people were able to perceive the colour blue because there was no word for it. Once the word existed, people identified the sky and sea as blue, while they had previously been assigned other colours or colourlessness. While consciousness is made up of many processes, the language center seems essential to conscious perception. 

While these experiments also support my claims about the non-existence of free will and true responsibility, they are here meant to show that we really do fabricate drafts of narratives in out mind. Our brain synthesizes various drafts into a coherent narrative, even when some information is inaccessible or incomplete. This narrative construction is a functional process, enabling individuals to maintain a consistent sense of self and understanding of the world, despite the underlying fragmentation of neural processes. 


### Grid Solution to the Binding Problem

An important idea in AI research is that neural networks can represent information in high-dimensional spaces, where different properties of stimuli are encoded along distinct dimensions or hyperplanes. For instance, the colour "red" and the concept of an "apple" might be represented in separate hyperplanes. James Garson proposed that the integration of these properties—perceiving a red apple—occurs when processing trajectories align across these hyperplanes, allowing for the coherent binding of features. This approach circumvents the classical binding problem of how two types of information interact. There is no interaction. One difficulaty in this might be that two units of information seem to either be bound or not bound together, but cannot be somewhat or partially bound. Separate hyperplanes would allow for such partial binding, since the trajectory in activation space might not be precisely along the dimensions of such property-hyperplanes. This solution could also only ever be a partial solution, since it might explain local binding, but doesn't explain global binding. It has been a critique that causality is too broad a term to explain global binding, since input-output relationships are so numerous in our brain that everything would have to be bound together. 

I believe that the solution to the binding problem consists of two parts. The first part involves grid cells, and the second part is our attention/narrative mechanism. While local binding is quite similar to the proposed hyperplane solution, it is better explained through the known neural mechanisms of grid cells. Global binding, on the other hand, is best understood in terms of small-world networks, a long-range consensus mechanism, and an model of attention. Importantly, the binding problem does not require us to abandon functionalism or computationalism.

Place cells and grid cells are well-researched types of neurons located in the hippocampus and entorhinal cortex, respectively. They are believed to play a crucial role in the entire neocortex as well. Essentially, a particular grid cell is activated when we occupy specific locations in physical space. For example, if we were playing football on a field, certain grid cells would activate only when we were at particular points on that field. There might be ten such points where the same grid cell would be activated whenever we were in these points vicinity. Research has shown that these activation points form a hexagonal pattern. One can visualize this as ten large circles drawn on the football field, each surrounded by six neighboring circles, which explains the hexagonal-shaped activation regions.
However, a single grid cell alone cannot differentiate between these ten distinct circles. If we relied on just one of these cells, we would be unable to differentiate between the ten possible locations. The solution to this lies in grid cell modules, which utilize different grid patterns with varying circle sizes and orientations. The overlapping activations of multiple grid cells within these modules allow for the reliable identification of a specific location on the field. With increasing number of grid cells in a grid cell module it becomes increasingly improbable to have two locations on the field where all the activations are the same.

Movement from one point on the field to another corresponds to a particular transformation in grid cell activations, which can be described as a "distance" in activation space. It is postulated that these distances are tracked by what Numenta refers to as displacement cells. Displacement cells function similarly to grid cells in that they cannot, on their own, represent a unique displacement. However, "the cell activity in multiple displacement cell modules represents a unique displacement in much the same way as the cell activity in multiple grid cell modules represents a unique location. [...] Note, a displacement vector not only represents the relative position of two objects, it also is unique to the two objects. Complex objects can be represented by a set of displacement vectors which define the components of an object and how they are arranged relative to each other. This is a highly efficient means of representing and storing the structure of objects. This method of representing objects allows for hierarchical composition."

In this way, grid cells or similar mechanisms can form representations of different object properties, effectively solving the local binding problem. The global binding problem is solved by the consensus mechanism between different functional modules. Hawkins et al write:
"One of the classic questions about perception is how does the neocortex fuse different sensory inputs into a unified model of a perceived object. We propose that the neocortex implements a decentralized model of sensor fusion. For example, there is no single model of a coffee cup that includes what a cup feels like and looks like. Instead there are 100s of models of a cup. Each model is based on a unique subset of sensory input within different sensory modalities. There will be multiple models based on visual input and multiple models based on somatosensory input. Each model can infer the cup on its own by observing input over movements of its associated sensors. However, long-range non-hierarchical connections allow the models to rapidly reach a consensus of the identity of the underlying object, often in a single sensation.
Just because each region learns complete models of objects does not preclude hierarchical flow. The main idea is that the neocortex has 100s, likely 1000s, of models of each object in the world. The integration of observed features does not just occur at the top of the hierarchy, it occurs in every column at all levels of the hierarchy."

On attention, they write: "One of the key elements of a location-based framework for cortical processing is the ability of an area of cortex to rapidly switch between object spaces. To learn there is a logo on the coffee cup we need to alternate our attention between the cup and the logo. With each shift of attention, the cortical grid cells re-anchor to the location space of the newly attended object. This shift to a new object space is necessary to represent the displacement between two objects, such as the logo and the cup. It is normal to continuously shift our attention between the objects around us. With each newly attended object the cortical grid cells re-anchor in the space of the new object, and displacement cells represent where the new object is relative to the previously attended object."

It can then be conjectured that our overall attention is also a shift between object spaces, where the object is, connected to the MDM, the winner in the competition of fame.


### Attention Schema Theory

I contend that Graziano's attention schema theory is subsumed by Gazzaniga's left-brain interpreter. Graziano proposed that an attention schema is like the body schema. Just like the brain constructs a simplified model of the body to help monitor and control movements of the body, so the brain constructs a simplified model of attention to help monitor and control attention. The information in that model, portraying an imperfect and simplified version of attention, leads the brain to conclude that it has a non-physical essence of awareness. The construct of subjective awareness is the brain's efficient but imperfect model of its own attention. This model of attention is practically identical to the interpreter described by Gazzaniga, i.e., the fabricated narrative is the narrative about our attention. In this view, consciousness is not a direct reflection of sensory inputs but a model- or narrative-based construct that provides the organism with an understanding of its own focus and mental states. The attention schema enables the brain to attribute awareness to certain stimuli, creating the subjective experience of consciousness, which aligns with the functionalist emphasis on the roles and interactions of mental processes. 

In the greater scheme of things the voting mechanism which decides about what drafts of narrative become famous and can therefore influence our behavior, is itslef made into a narrative by an interpreter in our mind. This narrative is what Graziano calls the attention schema, which is related to our memories in such a way that we would call these memories our experiences (that we were aware of). The primary adaptive function of the attention schema is to enable a better, more flexible control of attention. In the theory of dynamical systems control, a control system works better and more flexibly if it constructs an internal model of the item it controls. An automatic airplane-piloting system will work better if it incorporates a model of the dynamics of the airplane. An air and temperature controller for a building works better if it incorporates a rich, predictive model of the building's airflow and temperature dynamics. The brain's controller of attention works better by constructing a rich, internal model of what attention is, how it changes over time, what its consequences are, and what state it is in at any moment.

This model is essentially the narrative we perceive as that which we are aware of. The model itself might reside almost entirely in our brain's language-processing modules, but it is highly connected to every part of our cortex. It only becomes aware of the consensus within our cortex, but might influence the voting process itself, for it might influence the shifting of attention within the cortical object spaces.




## On Morality

Why is consciousness so tightly linked to morality? In questions regarding animal ethics, abortion ethics, AI ethics, or medical ethics consciousness is often a deciding factor for how to treat any being. 
Kant thought that humans had some kind of inherent dignity. But where does that come from? Philosophers have tried to answer this, but there is no actual answer. It somehow just has to be there, in order to make Kantian ethics work. 
The answer to both questions is really simple when one knows about Universalism. In Universalism Parfits argument, that personhood is based on psychological connectedness (relation R) is overcome and instead personhood is defined by our conscious experience of this and mine. 
By the immediacy of experience from the first-person PoV (for the full argument, see Zuboffs work). If this is accepted, then every being with this pattern of immediacy in its experience is the same person. By that logic, consciousness tells you, when another being is you. 
That is why consciousness is so important, because it distinguishes what is you and what not. And by doing that, it distinguishes what is of moral consideration and what not. There is no inherent dignity to humans, but it emerges from consciousness and Universalism.

### Hume's law
How to get an 'ought' from an 'is':

P1: One should only desire, what one really desires.

P2: There is only one subject of experience, every being is the same subject.

C: Everyone should only desire, what everyone really desires. 

Here we evade the is-ought problem by seemingly already including an 'ought'-statement in the premises, that's actually a fact. Now one would of course ask, how this ought-statement can be justified, but it is justified, because desire and believes are intimately connected. 
Arnold Zuboff gives the example of a cup of hot mud. Looking at the cup, I could believe it to be hot chocolate and may think that I desire it. But in reality my believe is wrong, which is why my real desire is to not drink from the cup. 
Applying this principle consequently to all my desires, requires for me to have a perfect grasp of reality. My only real desires are those I would have if I had a perfect grasp of everything involved. 
The principle going along with this that governs my actions must tell me to act, as far as possible, as I would want myself to be acting with a perfect grasp of everything involved. 
It would include within it, then, all the motivation of all of the various systems of desire, but it would also have the correction of all that motivation in light of the perfect grasp. The overall result must be a desire for the reconciliation of all systems of desire. 
This is not to say, that a perfect grasp of reality is desirable let alone achievable, but it describes the process by which we at least try to live by, because our mind automatically simulates and auto-corrects our desire in accordance with our believes. 
But is premise 1 really a factual statement? In this regard I think Sam Harris was right, when he said, that 'ought' and 'should' are verbal traps. They presuppose an objective perspective, from which morality can be evaluated, that does not exist. 
But if I just ask, 'should I drink from the cup?' I am not asking about a god-given rule, I'm only asking if I really desire to drink from the cup. It is not that deep. 'Should' is just a short-hand for 'real desire'. Therefore premise 1 is just a tautology aka a fact.

### Normative Fundamentals

A desire or will is always a call for change toward a desired future or more accurately against certain undesired futures. In a control system, these would be set points, but we can call them goals. The cause of our desire, whatever its origin, is called a motivation. 
The root of our motivations lies in our preferences and their root in well-being. Preferences allow us to rank different experiences based on their quality of well-being—that is, how much we desire them relative to one another. An ethical theory must take this into account. 
It is a famously unsolved problem that one cannot from is-premises derive an ought-conclusion. An ought-statement is a certain kind of want-statement or desire, because if I ought to do something, I would obviously want to do it, since it would be the right thing to do. 
Thus, what I ought to do must be what I would want to do if I knew what it was. The real question, then, is how to determine what I would truly want to be doing in a given situation. There is an answer to this question, but the answer is out of our reach: 
I would always want to do what I would want to do if I had a perfect grasp of everything involved. Since what I ought to do must be something I can actually do, there would be no further possible understanding beyond such a perfect grasp. 
I would take into account every perspective and information to reach the conclusion of what I would then actually desire and could be sure that there is nothing to change this desire anymore, because there is no further grasp to be gained about the situation. 
Since this desire could not be changed, it must be what we would ultimately want to do. It follows that I ought to do what I would want to do if I had a perfect grasp of everything involved. 
As noted above, any desire is ultimately motivated by well-being. If ought-statements are driven by desires, they are motivated by well-being and preferences. So I could also say that what I ought to do is what I would prefer doing if I had a perfect grasp of everything involved. 
With this in mind, universalism completes the ethical framework. If I say, "I ought to do what I would really prefer if I had a perfect grasp of everything involved", I can substitute "the universal subject" for "I", since everyone is the same subject according to universalism. 
This yields:

"I ought to do what the universal subject would really prefer if the universal subject had a perfect grasp of everything involved."

Notably, we cannot substitute "everyone" for the other "I" in that sentence, because it does not refer to the universal subject, but rather to the specific agent with its unique thoughts and influence on the world.

This principle shares similarities with Rawls' "veil of ignorance," but instead employs what Daniel Kolak calls the "veil of wisdom". 
Instead of ignorance it employs a perfect grasp (perfect knowledge and understanding) of everything. Instead of judging as if I was to be born into one, I need to be judging as if I was to be born into every conscious being. 
The result is an ethical framework that is fundamentally consequentialist-utilitarian in its pursuit of well-being, specifically aligning with preference utilitarianism, as it seeks to reconcile everyone's preferences. 
Even more specific would be the term "negative preference utilitarianism", because, as indicated in the beginning, a desire is a call for change, which would not arise if one is content with one's mental state. 
We do not desire some maximally specific future, but we prefer a future state that avoids what we want to avoid experiencing, which often results in the same overall goal (i.e. when there are only two options), but is more broadly applicable than utility-maximization. 
For example, if the only options are winning or losing, then avoiding to lose is the same as wanting to win. But in general, because we cannot precisely control or even predict the future, we can merely hope to evoke change in the right direction away from what we want to avoid. 
This is in line with Poppers views on science, where, since we cannot know the future, we can only ever hope to find theories that will not get falsified, but we can never actually obtain truth. 


### Ideal Observer Theory

The principle of perfect grasp is a type of ideal observer theory, making it cognitivist and subjectivist in nature. This means that ethical statements express propositions, which can be true or false, and where truth or falsity depends on people's preferences. 
This stands in direct opposition to non-cognitivism (such as expressivism), which asserts that ethical statements are not propositions and can only be honest or dishonest, but not true or false. To strengthen the principle of perfect grasp, we need to refute non-cognitivism. 
Expressivism is trivially false because ethical statements do not depend on emotion, if universalism is true. Any rational conscious being, even without emotions, or a psychopath, would necessarily need to agree with ethical statements derived from the principle of perfect grasp, 
because they will experience whatever they might otherwise inflict upon other conscious beings. If emotions are not necessary for ethical discourse, expressivism is obviously false, as it relies on emotional attitudes being the foundation of moral statements. 
Non-cognitivism is furthermore false because emotions are always functional states of interpretations of beliefs. Emotional expressions depend on the underlying beliefs that interpret all sensations. 
Even pain is not belief-independent, but rests on the belief that physical damage is harmful. This belief is so deeply ingrained in us (since even babies have this belief) that it seem more visceral and not like a usual belief. 
However, it is revealed to be one by people who have managed to overcome pain through meditation or otherwise. In psychology, it is a well-established fact (e.g. in the ABC model) that emotional reactions are responses to our beliefs. 
One could not experience specific emotions without corresponding specific beliefs. The claim that "moral statements are expressions of emotions" becomes (since emotions are expressions of beliefs) "moral statements are expressions of expressions of beliefs." 
Since beliefs are propositional (truth-apt) and can be right or wrong, emotions can be right or wrong as well.

So, even if the expressivist/emotivist claim were true, that ethical statements were just expressions of emotions of approval or disapproval, 
these emotions can still be right or wrong, depending on whether their underlying beliefs are right or wrong. For example, consider the desire to drink from a cup seemingly filled with hot chocolate, which actually contains hot mud. 
Your emotional expression of desire can be true or false, depending on what is actually in that cup, because your emotional expression is based on your beliefs about what the cup contains. Or think about your emotional expression of disgust upon seeing a pineapple pizza. 
This expression is only possible iff you believe there is something disgusting about pineapple pizza.

Beliefs can exist prior to emotions, but emotions cannot exist prior to the beliefs they express. 
One might ask, if one hasn't fully understood my claim, what could be right or wrong or true or false about an expression of pain. But I'm not claiming that the expression of pain is a belief in itself and could be right or wrong, but that it is an expression of a belief. 
A change in beliefs necessitates a change in expression of beliefs, which means a change in emotional expression. The pain in itself isn't right or wrong, but the beliefs underlying that pain can be, so I might not truly want to express pain, if my beliefs were different. 
This mean that beliefs are critical to any moral statement. Emotions cannot be explained without them and cannot be dealt with separately. Even though emotions are not propositions in themselves, they can still be right or wrong, depending on what beliefs they express. 

Zuboff summarizes: "I only ever desire a thing because of what I believe it to be. And since beliefs are correctable, so are desires. [...] My only real desires are those I would have if I had a perfect grasp of everything involved."


### The Intricacies of the Principle of Perfect Grasp

There are many intricacies about the principle of perfect grasp or what Arnold Zuboff calls the principle of best action. Let's explore a few of them to get a better understanding of what this view actually entails. 

1) "There could be a real desire to have another desire that was not itself real. For example, a child’s desire for an actual visit to the moon (as opposed to a fantasy visit) might be based on an ignorance of the visit’s difficulties and nastiness but might also, 
as an unrealizable desire, be harmless and fun to have. Thus having the desire might be really desirable. But being an object of a real desire would not turn the moon desire itself into a real desire. 
For the object of the real desire would be the moon desire and not the moon desire’s own object, the moon visit. The point of real desires is not at all that they would have been desirable to feel, as the moon desire would be. 
Real desires would anyway only be felt in a hypothetical perfect grasp of reality. The point of real desires is rather that they, and only they, as based on that perfect grasp of reality, have power to define for us which objects are really desirable 
(including perhaps a mistaken felt desire to visit the moon). From nothing more than such necessary truths about agency and desire springs the overriding motive of each and every agent to conform to the principle of best action, 
to do, as far as possible, what he would want if he had a perfect grasp of what he was doing."

2) "Real desires are those that would be had with a perfect grasp of reality. There are therefore real desires belonging to a rock, namely those it would have had 
with a perfect grasp of reality. [...] The perfect grasp contains all the angles. [...] The principle of best action requires the sort of reconciliation of all wills that would be formed in a perfect, and therefore merged, grasp by everyone of everyone and everything. 
Doing what is right for oneself turns out to be doing what is right for all those affected by one’s actions. Self-interest, transmuted through a principle that simply makes it consistent within itself, turns out also to be morality. [...] 
Morality and prudence have been revealed to be two characterizations of a single set of real desires. Morality is in their horizontal dimension, their responsiveness to others; and prudence is in their vertical dimension, their responsiveness to the future. 
Prudence is usually taken to be a self-interested farsightedness that will often conflict with morality. But morality and real prudence can never disagree, because morality, like real prudence, must agree with real self-interest." 
3) "Notice, by the way, that it is not rationality as such that is here being recommended. It might be a good thing in some respects not to be rational from time to time. But if we are irrational in assessing what is best, if our motivation is incoherent, 
that can prevent us from doing what is actually best for ourselves, what we would want ourselves to be doing grasping perfectly what it was we were doing. Rationality determines coherence, and what is important here is coherent motivation. 
That is the primary value of rationality for agents, though it has many secondary uses too. But rationality is not being worshipped here."

4) "A perfect grasp would have to comprehend at once, and perfectly, states of consciousness that essentially exclude one another. 
Perhaps this means that our hypothetical perfect grasp of reality is logically impossible. But, possible or not, omniscience is the inevitable ideal of our knowledge and the perfect grasp of reality is the inevitable hypothetical basis of an appropriate responsiveness to reality, 
which is the whole point of action. The perfect grasp need not be logically consistent to have this significance. [...] Let me mention a further feature of the perfect grasp that may make it impossible. [...] 
The perfect grasp must appreciate fully that what is important in the actual world is that the better possible experience become actual. In other words, although each potential experience must be fully grasped with all its compelling character, 
it must still be valued with regard to whether it should be made actual through action, as though the experience has not yet been had, as, indeed, it has not."

5) It would be ridiculous to regard the possession of the perfect grasp as a particularly desirable state to be in. In the actual, limited state of consciousness I happily have the option of avoiding any close acquaintance with either 
the frustration of not scratching or else the pain that follows scratching. The perfect grasp, however, must comprehend fully all the things I might want to avoid, combined, perhaps impossibly, with a full appreciation of all the escapes from them that might be had. 
So the principle of best action is badly misunderstood if it is taken to be recommending an actual perfect grasp or an actual feeling of one’s real desires, which would anyway be unattainable for us and perhaps contradictory. 
Neither does the principle, considered in itself, recommend truth, knowledge or an increased perception, appreciation or grasp of things in any degree whatsoever. Though an increased grasp of things will often be useful in deciding which actions are endorsed by the principle, 
and in carrying them out, and some increases in grasp would be discovered in a perfect grasp to be inherently desirable, the purely hypothetical perfect grasp that is mentioned in the principle is merely employed for its aptness 
in defining the best course of action for an actual, limited consciousness. [...] In fact, though a perfect grasp is necessary in the hypothetical state that would define best action, 
knowledge that is merely propositional will often be far preferable as a basis for the actual carrying out of such action. [...] A genuine perfect grasp of a pain, since it would contain within it the pain itself, would have all the motivational force of that pain. 
By contrast, the mere entertaining of a proposition, which only refers to or describes the pain with its words, will not in itself carry such motivational force. Yet there is a way I could try to bring to bear on my actions at least some of the absent force in the perfect grasp. 
[...] I would be creating an image of a missing content of the perfect grasp of what was relevant to my choice so that this missing content might yet throw some of its weight against the actual temptation in my
current perspective. [...] 
And perhaps, because I am rational, I can behave as though motivated by a pain that I do not have."

6) "A perfect propositional knowledge of everything that could be relevant to your choices, as opposed to the perfect grasp we have been describing, 
would be inadequate for defining your real desires and best action. As we have seen in the case of the itch, you can act against even the best of judgments when they
are in the form of propositional knowledge; 
this form does not in itself have the motivational force of the reality it represents. Only the sort of perfect grasp I have required could be certain to render you perfectly responsive to the reality of your actions."

7) "What if I sought a little pleasure [...] in attempting to solve a crossword puzzle? Such pleasure must depend on initially not knowing the puzzle’s solution. 
Since that solution would be fully grasped somewhere in a perfect grasp of reality, a person with the perfect grasp might seem incapable not only of valuing sadistic pleasure but also of valuing the rather innocent pleasure of filling in a crossword puzzle. 
Must the attempting of a crossword puzzle be condemned because it seems in this way inappropriate to a truly comprehensive state of consciousness? But the perfect grasp must be a perfect grasp of all the values within the limited grasps. [...] 
On the one hand, a perfect appreciation of reality must include a perfect empathetic grasp of actual and potential states of ignorance and distorted appreciation; and so it must include the pleasures of both sadism and crossword puzzles. 
Yet, on the other hand, the perfect grasp must also include an over-arching final assessment of these states in the light of full reality, including the reality of victims’ pains and the crossword puzzle solutions. [...] 
Here it is important to recall a point I made earlier, that a merely hypothetical grasp of reality must include a full grasp of its own actual unreality. If the person’s perfect grasp is merely hypothetical, 
the stress must be on the reconciliation of the only real states of consciousness, the limited ones, rather than on any hypothetical gratification of that person
in his non-existent synthesis of these states. [...] 
Imagine that you with a perfect grasp could shrink back to possessing only a limited consciousness, perhaps taking with you just the information you would need to make your life a satisfied one within that narrow compass. 
Well, after the shrinking your best action would still have to be defined by what you would have been deciding with a hypothetical perfect grasp of everything affected by your choices. The knowledge brought back to your limited consciousness could be a dangerous thing 
without reference to the perfect grasp of what it really was you were doing with that knowledge. Your real desires, the things you really want to be doing, are what that perfect grasp, and only it, represents. 
The point is neither to have that grasp nor to escape from it, but rather, as far as possible, to conform to what it would have had you wanting."

8) Another mistake about morality could be a fanaticism in the application of the principle of best action itself, 
having us always concerned about distant others and a distant future. If no special weight were given to oneself and those close to one, or to the present moment, much of human life, including that of similarly concerned others and future moments, would be poisoned, or starved.
Thus a moral concern for others may best be tempered by a particular concern with one’s own affairs. A prudential concern for the future may best be tempered by a respect for spontaneity and living in the present. 
Anyway, we often know more about ourselves and the present and can deal better with them. But none of what I been saying should be seen as a qualification of the principle of best action; it is what the principle itself must recommend. 
The principle has the power to absorb like a sponge all criticisms according to which it would be recommending anything undesirable, such as the self-defeating fanatical concern for others and the future that we have just rejected. 
The hypothetical perfect grasp itself must contain an appreciation of all such problems and any solutions. And it would include, as part of this, a full recognition of the limits and special needs of particular agents.


### The Value of life

Universalism leads to some new perspectives on ethics. One such perspective concerns the ethical value of life. Since the death of an individual is no longer synonymous with the death of their subjective experience, it follows that death is not inherently something to fear. 
Instead, death must be evaluated on a different basis than usual. The fear of death can no longer be understood as the fear of non-experience. Nor is it simply the fear of losing one’s memories, as storing those memories as a computer file would not alleviate this fear. 
To think clearly about this, we must consider the will to live and the will to die, each of which has its own reasons that can be ethically addressed. 
The will to live is, in reality, the desire for one’s thoughts to continue having an impact on the world. The will to die is, in reality, the desire to avoid certain experiences. To evaluate these desires ethically, we need to consider the principle of perfect understanding: 

1) Would one truly desire for one’s thoughts to continue having an impact on the world if one had a perfect grasp of everything involved?

2) Would one truly desire to avoid certain experiences if one had a perfect grasp of everything involved?


Almost everyone would answer the first question affirmatively, as most people believe in the positive value of their thoughts. However, opinions about the value of other people's thoughts are often more skeptical. 
The second question can also be answered affirmatively. A perfect grasp of the relevant factors would include a comprehensive understanding of our opinions, beliefs, and attitudes, as well as how to change them to eliminate suffering. 
Since the desire to die is fundamentally tied to avoiding suffering, one would not truly desire death with a perfect grasp of all factors, as suffering could always be avoided, which one would always want to do, since suffering is inherently what one wants to avoid. 
That said, this argument is not entirely practical, as avoiding suffering is not always straightforward. Ultimately, both questions must be evaluated in the context of specific circumstances and cannot have universally applicable answers. 
Notice that the question of whether one's thoughts should continue to have an impact is also a question about suffering, as one's thoughts are only valuable insofar as they contribute to moments of well-being. I'd argue that universalism aligns best with negative utilitarianism. 
This also aligns well with Popper's view, who made the observation that suffering obliges us to help, whereas there is no similar call to increase the happiness of someone who is already doing well, creating an asymmetry in favor of negative utilitarianism. 
The asymmetry originates from the fact that there are moments of experience one might want to change (those being moments of suffering) and moments one doesn't want to change (moments of well-being). 
One can be content with a moment and not wish to alter it, even if it isn't the best possible experience. As long as one is content with their experience, there is, by definition, no need for change and no call for action. 


### Population Ethics

Universalism has far-reaching consequences for population ethics. One specific problem in population ethics is the non-identity problem. This problem says that even a change that would, on the surface, seem to represent a clear improvement for a future person will often fail to make that person better off. Instead, it often serves only to bring another person, a "better-off person," but still a nonidentical person, into existence in place of the one we intended to help.
Under universalism, this view no longer makes any sense. 
Any future person is the same subject because their experience is immediate in first-person style. Therefore, universalism solves the non-identity problem, removing a key issue people have with longtermism. The distant future does matter! 
Another issue in population ethics concerns how to evaluate collective well-being. Even if there was a reliable measure for well-being, simply adding everyone's well-being leads to Parfits repugnant conclusion, while averaging everyone's well-being leads to his absurd conclusion. 
Both approaches depend on the assumption of separate identities, which falls flat under universalism.
This is not to say that averaging or adding well-being is inherently wrong. 
However, giving each being the same scale of well-being (e.g., from -100 to 100) purely because of their physical separation is flawed. In averagism, for instance, we divide total well-being by the number of people, but under universalism, this number is totally arbitrary. 
We could hypothetically split or merge brains however we wanted, changing the "number of people" without affecting the number of actual subjects, which always remains one.
Total utilitarianism seems more consistent with universalism, but it comes with its own challenges. 
E.g. Robert Nozick, raised the problem of the utility monster, where one being (perhaps an AI or a merged brain) is capable of experiencing such enormous happiness that it justifies the mistreatment of others to satisfy it. This makes utilitarianism non-egalitarian. 
Additionally, the repugnant conclusion states: "For any possible population of at least ten billion people, all with a very high quality of life, there must be some much larger imaginable population whose existence, if other things are equal, would be better, even though its members have lives barely worth living".

Both of these problems arise from trying to frame population ethics in terms of mathematical points of well-being or suffering per life. 
Instead, we should think in terms of moments of experience being added to the universal subject's experience. These moments cannot simply be reduced to discrete points of well-being, but they can be understood in terms of their functions, if functionalism is true. 
Happiness and suffering, therefore, are functions and ultimately functions of behavior. This means that the limits of behavior are the limits of well-being and suffering, making it impossible for a significantly deviating utility monster to exist. 
The repugnant conclusion, on the other hand, can be evaluated in the same way an individual might evaluate their own life: the question becomes whether one would prefer a short life with high well-being or a long life with low but still positive well-being. 
Viewed this way, the repugnant conclusion isn't even truly repugnant. If experiencing the world has intrinsic value for the person, as Nozick suggested in his experience machine thought experiment, then the repugnant conclusion might actually be favored by the universal subject. 
Total utilitarianism, therefore, seems to be correct under universalism. Ultimately, if the number of experienced moments is important, is up the population under examination and cannot be answered objectively. 

### Longtermism

Consider the thesis that "we should not aim for ethical principles". If this thesis is wrong, then we should aim for ethical principles. 
If it is true, then "we should not aim for ethical principles" would itself be an ethical principle to aim for, thereby undermining its own claim that we should not aim for them. This contradiction means that there are ethical principles we should aim for. 

To determine what those principles might be, it is necessary to apply the scientific method to test and investigate which principles work best. Most of our moral discourse on such principles has been shaped by neartermism. 
By this I mean a focus on goals that primarily benefit people who are currently alive. Such collective goals include equality, freedom, stability (which encompasses security and peace), solidarity, truth, or fairness. 
Such ideals have become central to many societies, yet upon deeper reflection, they are largely products of neartermist discourse, even though some can also be applied to future generations. 
In contrast, longtermism has emerged as an ethical perspective that advocates for additional goals that civilization should pursue. These include sustainability, progress, and civilizational safeguarding (which encompasses civilizational immune systems and expansion). 
Without aiming for these goals, civilization will sooner or later inevitably encounter various crises. It may self-destruct due to an unsustainable standard of living, the degradation of its own ecosystem, or a lack of moral progress, leading to value lock-in and stagnation. 
Stagnation, in turn, correlates with moral regression and creates the risk of civilization being unprepared to handle critical future risks, what some longtermists refer to as S-risks (suffering risks of enormous scope and severity). 
To mitigate these risks, longtermists call for civilizational safeguarding to prevent such catastrophic scenarios from actualization. One can conceive of various civilizational immune systems designed to avert foreseeable disasters, 
such as AI enslavement, superviruses, immortal dictatorships, grey goo, natural disasters (asteroids, solar flares, supervolcanoes etc.), nuclear war, and so on. 
Arguably, the only way for civilization to ensure its long-term survival is through expansion to other star systems, populating as much of the universe as possible to minimize the risk of self-destruction, external catastrophes or a dark forest scenario. 

There are many arguments against longtermism, and while they might succeed in challenging the idea that uncertain future lives should be valued as highly as certain present lives, they do not refute the fundamental longterm ethical principles outlined here. 
One might claim that future generations should be responsible for solving their own problems while we focus on ours. But in the case of these longtermist principles, the issue is precisely that future people may no longer be capable of solving their problems 
if we are too complacent in accepting the lock-in of certain values, stagnation, or unsustainable technologies. While addressing these challenges may be relatively easy now, they may become significantly more difficult over time, much like what has happened with global warming. 
Longtermism is further strengthened by universalism, which clarifies that the suffering of future beings is just as much yours as the suffering you experience in your present life. 
According to the principle of perfect grasp, if one were to fully grasp everything involved, one would naturally seek to prevent futures of immense suffering, for one will otherwise unavoidably experience all that suffering. So this is what we should strive to do.


### Practical application

There are many possible analogies to approximate the previously derived ethical rule:

"I ought to do what the universal subject would want to be doing if the universal subject had a perfect grasp of everything involved." 

I will discuss the two most helpful analogies and how they address ethical questions.

1. The Time Traveler Analogy:

Imagine that every other person in a given ethical situation is actually yourself, who has time-traveled back, erased your memories, switched bodies, and adopted the personalities of the people involved. If you fully grasp this mental exercise, you would naturally try to help others in need to the best of your ability because you'd recognize that you will one day be in their shoes. 
Peter Singer’s argument in Famine, Affluence, and Morality becomes obvious under this perspective: helping others is rational because their suffering is ultimately your suffering. But it will also be obvious that Singer's conclusion that such actions are obligatory is mistaken. 
Obligations require that others are truly other identities. You cannot have obligations to yourself. Instead, failing to help would simply be irrational, like refusing to treat your own wound. You don’t have to treat it, but ignoring it would only cause you more suffering. 
The time-traveler analogy can be used in many different ethical situations: helping people in need, helping the lower class, helping migrants, arguing for conditional pacifism or human rights, explaining the wrongness of racism or eugenics etc., creating rational empathy. 

2. The Reincarnation Analogy:

In this analogy, you imagine dying and having the opportunity to choose your next life, similar to Rawls "original position". Suppose you are presented with the option of reincarnating into an available body or skipping to the next one. 
Some lives, particularly those filled with extreme unnecessary pointless suffering, would be lives not worth living and you would probably skip them, if you could.
This analogy helps clarify ethical questions regarding e.g. abortion or antinatalism. 
Since I am ultimately the same subject in all lives, I do not have an obligation not to abort another being. I would simply be ending another potential instantiation of myself, which cannot harm me in any way. 
However, if a given reincarnation would lead to unbearable suffering, it would be irrational not to skip it. Just as I would choose to avoid a deeply painful situation in my current life if given the option, it would be rational to prevent such lives when possible. 
This reasoning extends directly to veganism. If I am to be reborn as every conscious being, then I will also live through the lives of factory-farmed animals, experiencing their suffering firsthand. 
Given the horrific conditions in which these animals are raised and slaughtered, I would want to skip those lives whenever possible. The rational choice, then, is to end the industries that create such suffering. 
Given the cultural hurdles, the most impactful option would be to contribute to the development of in-vitro meat and precision fermentation.

Given all this and given the fact that we should prioritize reducing suffering, these analogies might seem to favor antinatalism. 
After all, one could reduce suffering by skipping all incarnations ending conscious experience entirely. But 1st of all, the principle of perfect grasp is a maximization principle seeking the best outcome (positive utilitarianism), not avoiding the worst (negativ utilitarianism). 
Prioritizing suffering is therefore not a dogmatic principle, but a practical suggestion.
Second of all, antinatalism, if it were desirable, would only work inside the light-cone a certain civilization occupies. We can never influence the suffering outside of our light-cone. 
Therefore, destroying life is not a rational objective, because the universal subject would experience all the other lives outside our light-cone anyways. Instead, the best we can do is to contribute to the positive experiences of the universal subject as much as we can. 

### Negative Utilitarianism and the Trolley Problem

I argued that negative utilitarianism is best understood as a practical guideline rather than a fundamental ethical principle. The principle it proposes is:

An act is right if and only if it minimizes the total sum of suffering.

The corresponding positive principle would be:

An act is right if and only if it maximizes the total sum of well-being.

But the trolley problem and the more extreme transplant problem demonstrate why negative utilitarianism cannot serve as the ultimate ethical foundation. 
Here's the original Trolley Problem:

"Edward is the driver of a trolley, whose brakes have just failed. On the track ahead of him are five people; the banks are so steep that they will not be able to get off the track in time. 
The track has a spur leading off to the right, and Edward can turn the trolley onto it. Unfortunately there is one person on the right-hand track. Edward can turn the trolley, killing the one; or he can refrain from turning the trolley, killing the five." (Thomson 1976, 206) 

And here's the original transplant problem:

"Donald is a great diagnostician. Five of his patients are dying. By chance Donald learns of a healthy specimen such that if Donald cuts him up into bits, a peculiar physiological process will be initiated in the five, curing them. 
Donald can cut his healthy specimen up into bits, killing him, thereby saving his patients. Or he can refrain from doing this, letting his patients die." (Thomson 1976, 214) 

At first glance, negative utilitarianism might suggest that we should minimize the number of deaths, since one person dying results in less immediate suffering than five people dying. However, this view fails to account for the total suffering involved. 
The five survivors in these scenarios would likely experience suffering—both from the traumatic experience and from ongoing difficulties in their continuing lives. Their collective suffering could easily exceed that of the single individual, if its life continued. 
The problem becomes even more pronounced when we scale up the numbers. If a thousand people are in danger, negative utilitarianism would suggest that their combined suffering would far outweigh that of a single individual and should be eliminated. 
This logic leads to an obviously unethical conclusion: that systematically eliminating as many people as possible would be the best action to take. Clearly, this contradicts what we would truly want to do if we had a perfect grasp of everything involved. 
This conclusion arises because it completely neglects the fact that there is a desirable state of mind, we call well-being and not just an undesirable state of suffering. To optimize the experience of the universal subjects, we need to think about the desirable and undesirable.

### Team formation

Generally, team formation is seen as a positive development, as it unites people behind a common cause. The mindset associated with this is called the 'soldier mindset' by Julia Galef. However, team formation could just as easily be seen as creating division and exclusion. 
Beyond practical purposes, it leads to self-deception through motivated reasoning. People begin to integrate these causes into their identities, so that any attack on these feels like an attack on their entire identity, leading to polarization and radicalization. 
Galef therefore recommends adopting the 'scout mindset' to benefit from practical team formation while embracing truth as the team’s guiding cause, countering motivated reasoning. If we align ourselves with seeking truth, there are no enemies to our team. 
Any other team formation necessarily ignores that what one does to the enemy, one ultimately does to oneself, since we are ultimately the same subject. Political, religious, or economic team formation, beyond its practical uses, should therefore always be seen as unhelpful.






## On Free Will


Universalism and incompatibilism share many counter-intuitive ethical consequences, making it highly improbable for these concepts to have any role in a hypothetical science of ethics. As a result, consequentialist-utilitarian ethics is way more persuasive. 
If both incompatibilism and universalism are true, then concepts such as blame, retribution, obligation, and responsibility are rendered incoherent.
Under universalism, obligation is untenable because obligation presupposes a relation between distinct individuals. 
If I inflict harm upon myself, I do not have an obligation to myself to cease my own suffering. But given that I am everyone, it follows that I cannot have obligations toward others, since there are no true "others" distinct from myself. 
But all the other listed concepts, blame, retribution, and responsibility, ultimately depend on the coherence of obligation. If no one has obligations, then it is impossible to blame anyone for harming another in the retributive sense, for the blamer and blamed are the same. 
To blame another would be equivalent to blaming myself for harming myself. While I may regret my past actions, I would not, on that basis, intentionally inflict further suffering upon myself as a form of retributive response. 
Thus, for the universalist, both blame and retribution are irrational.
If obligation is incoherent, then responsibility is equally untenable. Responsibility presupposes that an agent is accountable for their actions in a way that distinguishes them from the actions of others. 
But if I am everyone, then I would necessarily be accountable for all actions universally. This kind of responsibility, one that depends on the attribution of actions to the personhood of persons, is nonsensical. 
The only entity to which an action can meaningfully be attributed is a particular intention corresponding to a particular conscious brain.

Incompatibilism leads to the same conclusion through another line of reasoning. 
Responsibility is only possible in a substantive sense if libertarian free will exists, that is, if responsibility entails causal sourcehood or control, rather than mere conscious identification. The latter is insufficient for blameworthiness. 
If I consciously identify with the intentions that led me to harm another, I am still nothing more than an observer of those intentions. My identification with them is simply a consequence of the physical processes within my brain, over which the observer has no ultimate control. 
But a helpless observer cannot be held morally responsible for anything. The agent who performed the action—like a falling tree, following physical laws, causes harm—may be causally responsible for the resulting suffering, but cannot be subject to blame or punishment. 
If one would not punish a baby who unintentionally causes harm, or a person whose violent actions are the consequence of a brain tumor and who ceases to act violently upon its removal, then no one can justifiably be punished, since everyone is equally powerless in their actions. 
If responsibility collapses, then all associated deontological concepts collapse as well. Retribution becomes incoherent because punishment becomes arbitrary. We do not punish a tree for falling, for it can't do anything against its descent; 
likewise, no person has true control over their actions, and thus retribution cannot be meaningfully applied.
Certain additional moral concepts become incoherent from the standpoint of universalism, even though they remain compatible with incompatibilism. 
For instance, the concept of justice as fairness is flawed. Fairness presupposes a demand for equality between distinct persons. If two players engage in a game, the game is fair only if both abide by the same rules. 
However, for a universalist, every game is ultimately a game in which I play against myself. If I play a game where I pretend to be two separate players, A and B, it is ultimately irrelevant which player wins, because I am both. 
Similarly, concepts such as ownership and theft become incoherent, for one cannot steal from oneself. This can be illustrated through the time-traveler analogy: Suppose my future self from tomorrow travels back in time and claims ownership over my present possessions. 
Who rightfully owns them, the present self or the future self? Since both are the same person, both own the possessions. But, under universalism, because everyone is the same person, it follows that everyone would own all possessions, including mine. 
Consequently, ownership must be attributed to something else about the agent other than the person, if it wants to remain a coherent concept. Yet, as we have established, the agent was never free in any meaningful sense, bringing us back to incompatibilism. 
Here, the concept of deservingness is rendered incoherent, though not necessarily under universalism. We cannot deserve anything, for we've never been in control of our actions. While ownership may have pragmatic utility, it can't be justified on the basis of desert either. 
And it cannot be justified on the basis of personhood. By the same reasoning, meritocracy can at best be pragmatically, but never morally, justified, if we define it as: "If initial chances are equal, the winner deserves the gain", since deservingness isn't real. 
The truth of these claims is easier to recognize, if we think about the long-term future of humanity. We are already moving in this direction of giving up ownership and we'll soon need to rethink meritocracy, when the merit of AI outpaces all of us.


### The Compatibilist Confusion

I think the compatibilist confusion originates from two distinct concepts of control as foundations for free will. To distinguish these, I will refer to the first type as regulatory control and the second as ultimate or true control. 
Regulatory control is the kind of control central to control theory in engineering. For example, if a thermostat regulates temperature, it can be said to have regulatory control—there is a causal dependency of temperature on the thermostat. 
It has a given control loop and a certain response function to a given temperature input. The output causally depends on the input.

Ultimate control, on the other hand, is equivalent to determination, where "to determine an action" means to be the ultimate cause of that action. 
The Consequence Argument easily demonstrates that this kind of control is impossible. If determinism is true, then events from a million years ago already determined my actions, meaning I cannot have been their ultimate cause and therefore lack true control. 
Peter van Inwagen's argument is even more precise:

"If determinism is true, then our acts are the consequence of laws of nature and events in the remote past. But it's not up to us what went on before we were born, and neither is it up to us what the laws of nature are. Therefore, the consequences of these things (including our present acts) are not up to us" (p. 56).

Van Inwagen makes the great point that there are seemlingly touchable and untouchable facts, that is, facts in our control and facts we cannot do anything about. The latter would include that 1+1=2 or that 317 is a prime number or that dinosaurs existed or that opposite charges attract each other. Seemingly tochable facts would be the decision what to eat on a particular day or what to say in a conversation. But if there is some proposition P, which is untouchable, and Q follows from P, then Q must also be an untouchable fact. Since determinism holds that for any state Q there is a preceding state P that causally determined Q, then, since whatever happened millions of years ago is an untouchabel fact, any state of the universe after that is an untouchable fact, without any ultimate control on our part.

What would be required for such ultimate control though, is not an indeterministic process (as some might claim), since I would not be the cause of that either. 
Rather, what's needed is complete independence of my functional outputs from the inputs I receive. To be truly in control, I must be able to decide independently of my inputs what to do. If my outputs are determined by my inputs, then I am not the ultimate cause of my actions. 
Only if I could originate an event uncaused by the laws of physics would I truly be the ultimate cause. But since this is impossible, free will of this kind is likewise impossible.
Compatibilists can attempt to salvage free will by weakening the requirement of independence. 
However, in doing so, they recover only regulatory control, which is not what free will is truly about. Daniel Dennett, for instance, argues that if our complex control loops function well, then we have free will. 
But this is no different from a thermostat functioning well and claiming that it, too, has free will.
The primary motivation for compatibilism is to preserve moral responsibility, as it may seem that without free will, responsibility collapses. So, are thermostats blame-worthy? 
Compatibilists might also argue that “if the agent had wanted to do otherwise, then he would have done otherwise” is sufficient for free will. However, this is clearly inadequate, since—if determinism is true—the agent could not have wanted to do otherwise. 

Then there's the Principle of Alternative Possibilities (PAP):

P1: An agent is responsible for an action only if the agent could have done otherwise.

P2: An agent could have done otherwise only if causal determinism is false. 

Conclusion: Therefore, an agent is responsible for an action only if causal determinism is false.

Harry Frankfurt challenges the first premise by arguing that alternative possibilities are not necessary for moral responsibility. 
His Frankfurt cases have their own problem (e.g. the two-horned dilemma). But even if we reject PAP, this is not sufficient as an attack on the actual free will principle: An agent is responsible for an action if and only if they are its ultimate cause. 
Since Frankfurt cases do not establish ultimate control, they fail to preserve genuine responsibility.

Does this mean that responsibility does not exist? Yes. However, this does not contradict preventionist punishment, and accountability remains intact, too. 
We can still assign actions to agents and hold them accountable, even if they are not ultimately responsible for them.
The condition for accountability can simply be that the agent consciously identifies with their actions at the moment for which they are held accountable. 
If I were asleep or hypnotized when performing an action, I would not be truly accountable because I was not conscious of it. In essence, an agent is accountable for an action if, at the moment of action, they recognize themselves as accountable for that action. 
The moment-condition is necessary to prevent cases where external manipulation, like implanting a chip to alter an agent’s sense of responsibility afterward, could falsely absolve them of accountability. To be accountable, one must have felt accountable at the moment of interest.

### Accountability

I argue that compatibilists are not actually debating free will or what it truly means to be responsible for an action, but rather the concept of accountability.

If we frame the discourse this way, there are actually interesting arguments about what qualifies as morally accountable. 
For instance, John Martin Fischer subscribes to the idea that moral responsibility requires what he terms guidance control, as opposed to what he terms regulative control (not to confuse with what I termed regulatory control). 
Regulative control would necessitate genuine metaphysical access to alternative possibilities, which implies causal independence between inputs and outputs. If determinism is true, such causal independence is impossible. 
(The reasoning is that causal independence necessitates alternative possibilities, but alternative possibilities do not necessitate causal independence. A truly indeterministic process would also enable an agent to have done otherwise, without the agent being the ultimate cause.) 
Fischer’s concept of guidance control is then essentially what I have termed regulatory control, and his argument for moral responsibility is, in reality, an argument for moral accountability. Even though he refers to it as responsibility, I will now call it accountability. 
His concept of accountability requires "reasons-sensitivity of the appropriate sort and mechanism ownership." What he calls mechanism ownership corresponds to what I describe as consciously identifying with one's actions in order to be accountable for them.
Fischer explains: 
"One’s mechanism becomes one’s own in virtue of one having certain beliefs about one’s own agency and its effects in the world, that is, in virtue of seeing oneself in a certain way. 
(Of course, it is not simply a matter of saying certain things—one actually has to have the relevant constellation of beliefs.) In my view, an individual becomes morally responsible in part at least by taking responsibility." 
The requirement of reasons-sensitivity is a crucial addition, as it prevents accountability in cases of brainwashing/manipulation.

Alfred Mele critiques the Fischer-Ravizza approach with several counterexamples: 
For instance, a person who believes they had no choice, yet still sees themselves as responsible, would not actually be responsible according to the approach. However, if we are talking about accountability, this is not a problem. 
One only needs to identify with one's actions to be accountable, not necessarily perceive oneself as responsible or as the source of those actions. Even an addict who does not truly want to act on their addiction must still, in some way, identify with their actions. 
Only dissociative disorders could pose a challenge to accountability of this sort.
Another counter from Mele involves a person with a phobia, where one fear overrides another and leads to an immoral decision—one that would not have occurred if events had unfolded differently. 
Such a person is still reasons-responsive but might not necessarily be considered morally accountable due to their phobia. 
Fischer responds by arguing that reasons-responsiveness can be divided into different spheres of responsiveness, where phobia-driven actions would be placed in an outer sphere, potentially lacking sufficient responsiveness for moral accountability. 
I do not think this distinction is necessary and would maintain that phobias do not negate accountability. Like the Stoics, I believe that yielding to one's emotions is a choice rather than an inevitability, as Dennett might have also pointed out. 
Ultimately, I'd conclude that Fischer’s approach to accountability is essentially correct:
An agent is accountable for their actions if and only if they consciously identify with their actions and are appropriately reasons-responsive at the moment of action. 


### Stoicism and Compatibilism

Stoicism is not often framed this way, but it is fundamentally a philosophy based on compatibilism. To the extent that this is possible, the Stoic view largely aligns with my view. The Stoics fully embraced determinism. 
Stoicism holds that one can only genuinely control one’s own thoughts, and that it is our thoughts, not external circumstance that we should focus our attention on. While we do not have true control over our thoughts, we possess a crucial form of regulatory control: 
the ability to anticipate, reflect, and reason through different possibilities. Unlike a simple thermostat, which passively responds to inputs, the human brain can reason through and weigh different outcomes as well as regulate its own regulatory processes. 
This meta-control grants us a degree of independence that a thermostat cannot achieve. It doesn't give us the independence needed for true control, but it can be seen as approaching such independence. 
Imagine a scenario in which your brain is placed in a vat and stimulated to experience a virtual reality where you exist in a white room with only two values displayed on a screen: the outside temperature and the inside temperature. 
You can regulate only the inside temperature, essentially making you a thermostat. In this case, your brain no longer receives direct input from the real world and is, in a sense, independent of it. 
While external conditions (the outside temperature) still influence your decisions, most of your reasoning about how to adjust the inside temperature arises from internal cognitive loops, rather than direct external stimuli. 
Your behavior is still physical and therefore causally determined without any true control on your part, but you still possess significantly more independent autonomy in your immediate environment than a thermostat. 
Stoicism is fundamentally a philosophy of self-regulation within a deterministic universe.

The stoics recognized that value and control are nearly indistinguishable. One is the the motivation, the other is the action of desire. 
In other words, we attempt to control whatever we value, because valuing something inevitably leads to desire, and we cannot help but act on our desires, unless a stronger competing desire restrains us. 
The search for free will or for control becomes, in essence, the search for what one truly values. The Stoics recognized this and built their ethics around the idea that eudaimonia comes from properly aligning our values with what is actually within our regulatory control. 
This is why Stoicism emphasizes the cardinal virtues, wisdom, justice, courage, and self-control. These virtues are not arbitrarily chosen; they are precisely those qualities that help refine and optimize our self-regulation. 
As Albert Ellis said, mistakes are almost always based on ignorance, stupidity, or emotional disturbances. 
The value of wisdom is intended to shield us from ignorance and stupidity, justice is meant to guard us against the selective thinking driven by our intrinsic selfishness that disregards the fate of others (a similar suitable virtue of this category would be empathy). 
Courage protects us from making mistakes out of fear, and self-control shields us from mistakes driven by irrational passions. 
In other words, the Stoic ideal is not about having "free will" in the metaphysical sense but about achieving optimal self-regulation (mental health), controlling what can be controlled and ceasing to desire control over what cannot.

### Against Retributivism

Arnold Zuboff has also argued against retributivism and for incompatibilism. 

He writes: "Think of an evil agent, one who deserves punishment. Think of the man who put pieces of glass in baby food in order to extort money from the baby food company. 
Now imagine you become convinced that this evil man had been assembled, the night before he launched his disgusting scheme, by an advanced sort of Frankenstein, a mad scientist capable of constructing from the raw materials of living things not a mere automaton, 
but a completely human-like being, with a brain supporting a mind that has in it the same pattern of conscious and unconscious mental life that we would have assumed this man had when we started thinking about him as our example of an evil agent. 
Since we have stipulated the internal sameness of this man with the man as he would be in the normal case, he himself will not know he was manufactured by the scientist. He has a complete set of memory impressions of having been a child, of a bank balance, etc., 
as well as all the same motivation he would have had in the natural case. So he does the awful deed. Now what do we think of him? My reaction is to think he is bad and ought to be stopped and, if this is possible, changed. 
What I no longer seem to feel is that he deserves to suffer, great pangs of guilt as well as what we decent people will do to him. I no longer feel that there’s an intrinsic good, a good apart from such possible consequentialist goods as reform or deterrence, 
in his feeling the pain of punishment because in some deep sense he deserves the pain. I see now too clearly for that that he is merely a product, with a nature chosen not by him but his manufacturer. [...] 
When I consider my reaction to thinking of this agent as a product of the mad scientist, it seems to me that my usual retributive feeling has drained out of me. Someone might be tempted to feel that the scientist deserves the punishment for choosing this evil nature 
for his creature. And, just for the fun of it, I could next ask the one who thought of this to imagine that the scientist too had been, without his knowledge, similarly created the night before he did his work by yet another such scientist. 
But this just delays our coming to the real point: what possible moral relevance can there be in the difference between the normal, actual case and this science fiction one? In contrast to our artificial man, the natural man in the actual case was produced 
by a less organized set of causes--heredity, environment, maybe initially God. But he, just like our artificial man, simply must act according to what he is--according to a nature which is internally indistinguishable between the two cases. 
If we try thinking that, be he natural or artificial, some of his actions may have been somehow uncaused, this would only threaten to remove from him even the sort of responsibility that bad weather may have for a bad harvest. 
Yet we are all vulnerable to the illusion that a thinking being cannot really be limited by his own nature--that he is always free to rise above it and improve upon it. 
Of course, thank God, a person can resolve to improve himself and can do so, but surely this will only happen when that was in his nature, in that very self-reflection that must seem to the agent to be indeterminate. 
I contend that no agent can be conceived of that could ever be responsible in the way required by retributivism. First, no agent could be responsible in any sense for his own beginning. In particular, he could not before he existed have chosen his own nature. 
[...] And even if, like God in the ontological argument, he existed with necessity from his own nature alone, he would have had no choice in either his existence or his nature. Next, only as far as he himself shapes his later nature can he be thought responsible in any sense 
for that, but such self-improvement or self-corruption cannot make him responsible for his nature in the way required for deontological desert. For, apart from either external causes or a metaphysical spontaneity for which nothing could be responsible, 
this self-determining can only depend on his original unchosen nature or later developments of that. Finally, the agent cannot be held responsible in the required sense for any of his actions, whether these are thought of as determined by the nature he essentially did not choose 
or as bubbling forth somehow undetermined and thus with nothing responsible for them in any sense. I conclude we should cure ourselves of this mode of judgment that has caused such great suffering in the bitterness of the judge as well as in the pain of the needlessly punished. 
But what of the Kantian view, already mentioned, that the agent when he acts morally, since he is then purely rational, can be free of all the particular, contingent conditions that seem to have formed him? 
Kant certainly thought that this sort of autonomy invested an agent with the responsibility required for deontological desert (although it seems to me this could authorize only reward, not punishment, since to be rational and autonomous was to be good). 
I think this fails, because if the agent’s motivation is somehow fixed timelessly by the forms of rationality, this is not freedom but necessity--it involves no choice. 
Neither could the agent, in the formation of his nature, have chosen either whether he was to be capable of rationality or whether he was to be disposed much to use it. 
(These same points apply to the idea that what we are entitled to punish retributively is the evil nature of the agent. Anyway, we can’t either punish or sensibly blame for being evil the property of being evil.)"
